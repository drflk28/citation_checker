import asyncio
import time
import uuid
import re
import os
from typing import Dict, Any, List, Optional
from ..models.data_models import (
    AnalysisResult, Citation, BibliographyIssue, BibliographyEntry,
    AnalysisStatus, IssueType, ParsedDocument, TextBlock, TextBlockType
)
from app.document_parser.universal_parser import UniversalDocumentParser
from app.citation_parser.citation_extractor import CitationExtractor
from app.bibliography.checker import BibliographyChecker
from app.bibliography.semantic_matcher import semantic_matcher
from app.services.library_service import library_service
import logging
import requests
import json
class SimpleAnalysisService:
    def __init__(self):
        self.document_parser = UniversalDocumentParser()
        self.citation_extractor = CitationExtractor()
        self.bibliography_checker = BibliographyChecker()
        self.analysis_results: Dict[str, Dict[str, Any]] = {}
        self.analysis_status: Dict[str, Dict[str, Any]] = {}
        self.semantic_matcher = semantic_matcher
        self.logger = logging.getLogger(__name__)

    def update_status(self, doc_id: str, stage: str, progress: int = 0):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç —Å—Ç–∞—Ç—É—Å –∞–Ω–∞–ª–∏–∑–∞"""
        if doc_id not in self.analysis_status:
            self.analysis_status[doc_id] = {
                'stage': stage,
                'progress': progress,
                'last_update': time.time()
            }
        else:
            self.analysis_status[doc_id].update({
                'stage': stage,
                'progress': progress,
                'last_update': time.time()
            })

    def get_analysis_status(self, doc_id: str) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –∞–Ω–∞–ª–∏–∑–∞"""
        return self.analysis_status.get(doc_id)

    def analyze_document(self, file_path: str, doc_id: str) -> Dict[str, Any]:
        try:
            print(f"üöÄ –ù–ê–ß–ò–ù–ê–ï–ú –ê–ù–ê–õ–ò–ó –î–û–ö–£–ú–ï–ù–¢–ê {doc_id}")
            print(f"üìÅ –§–∞–π–ª: {file_path}")
            print(f"üìä –°—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª: {os.path.exists(file_path)}")

            import time
            start_time = time.time()

            temp_result = {
                'doc_id': doc_id,
                'status': 'processing',
                'citations_found': 0,
                'issues_found': 0,
                'bibliography_entries_found': 0,
                'citations': [],
                'issues': [],
                'bibliography_entries': [],
                'summary': {}
            }
            self.analysis_results[doc_id] = temp_result

            # 1. –ü–∞—Ä—Å–∏–Ω–≥ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            print("üîç –®–∞–≥ 1: –ü–∞—Ä—Å–∏–º –¥–æ–∫—É–º–µ–Ω—Ç...")
            try:
                document = self.document_parser.parse_document(file_path)
                print(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω: {len(document.main_content or [])} –±–ª–æ–∫–æ–≤")

                if not document.main_content:
                    print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: main_content –ø—É—Å—Ç!")
                    result = {
                        'doc_id': doc_id,
                        'status': 'completed',
                        'citations_found': 0,
                        'issues_found': 0,
                        'bibliography_entries_found': 0,
                        'citations': [],
                        'issues': [{
                            'type': 'parsing',
                            'description': '–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞',
                            'severity': 'high',
                            'suggestion': '–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –≤ –¥—Ä—É–≥–æ–º —Ñ–æ—Ä–º–∞—Ç–µ'
                        }],
                        'bibliography_entries': [],
                        'summary': {
                            "total_references": 0,
                            "missing_references": 0,
                            "unused_references": 0,
                            "duplicate_references": 0,
                            "bibliography_entries": 0,
                            "valid_bibliography_entries": 0,
                            "completeness_score": 0
                        },
                        'error_message': None
                    }
                    self.analysis_results[doc_id] = result
                    return result

            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
                import traceback
                traceback.print_exc()

                result = {
                    'doc_id': doc_id,
                    'status': 'error',
                    'citations_found': 0,
                    'issues_found': 0,
                    'bibliography_entries_found': 0,
                    'citations': [],
                    'issues': [],
                    'bibliography_entries': [],
                    'summary': {},
                    'error_message': f'–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {str(e)}'
                }
                self.analysis_results[doc_id] = result
                return result

            # 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ü–∏—Ç–∞—Ç
            print("üîç –®–∞–≥ 2: –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏—è...")
            try:
                citations_result = self.citation_extractor.extract_citations(
                    document.main_content or []
                )
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ü–∏—Ç–∞—Ç: {citations_result.get('total_unique', 0)}")
                print(f"üìù –ü—Ä–∏–º–µ—Ä—ã —Ü–∏—Ç–∞—Ç: {citations_result.get('citations', [])[:5]}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ü–∏—Ç–∞—Ç: {e}")
                citations_result = {
                    'total_unique': 0,
                    'citations': [],
                    'details': []
                }

            # 3. –ü–æ–∏—Å–∫ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏–∏
            print("üîç –®–∞–≥ 3: –ò—â–µ–º —Ä–∞–∑–¥–µ–ª –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏–∏...")
            try:
                bibliography_blocks = self.bibliography_checker.find_bibliography_section(
                    document.main_content or []
                )
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –∑–∞–ø–∏—Å–µ–π: {len(bibliography_blocks)}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏–∏: {e}")
                bibliography_blocks = []

            # 4. –°–æ–∑–¥–∞–µ–º –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –∑–∞–ø–∏—Å–∏ –∫–∞–∫ –ø—Ä–æ—Å—Ç—ã–µ —Å–ª–æ–≤–∞—Ä–∏
            print("üîç –®–∞–≥ 4: –°–æ–∑–¥–∞–µ–º –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –∑–∞–ø–∏—Å–∏...")
            bibliography_entries = self._create_bibliography_entries(bibliography_blocks)

            # 5. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–Ω–ª–∞–π–Ω-–ø–æ–∏—Å–∫ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏ (—Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
            print("üîç –®–∞–≥ 5: –£–ª—É—á—à–∞–µ–º –∑–∞–ø–∏—Å–∏...")
            try:
                enhanced_entries = self.bibliography_checker.enhance_with_online_search(
                    [BibliographyEntry(**entry) for entry in bibliography_entries]
                )

                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å–ª–æ–≤–∞—Ä–∏
                bibliography_entries = []
                for entry in enhanced_entries:
                    entry_dict = {
                        'id': entry.id,
                        'text': entry.text,
                        'position': entry.position,
                        'is_valid': entry.is_valid,
                        'is_verified': entry.is_verified,
                        'matched_citations': entry.matched_citations,
                        'enhancement_confidence': entry.enhancement_confidence,
                        'search_queries': entry.search_queries,
                        'online_metadata': self._ensure_serializable(entry.online_metadata),
                        'library_match': self._ensure_serializable(entry.library_match)
                    }
                    bibliography_entries.append(entry_dict)

                print(f"‚úÖ –£–ª—É—á—à–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π: {len(bibliography_entries)}")
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è –∑–∞–ø–∏—Å–µ–π (–ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ —É–ª—É—á—à–µ–Ω–∏—è): {e}")
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–º–∏ –∑–∞–ø–∏—Å—è–º–∏

            # 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è
            print("üîç –®–∞–≥ 6: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ü–∏—Ç–∞—Ç –∏ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏–∏...")
            try:
                if bibliography_blocks:
                    validation_result = self.bibliography_checker.check_citations_vs_bibliography(
                        citations_result['citations'],
                        bibliography_blocks
                    )

                    # –û–±–Ω–æ–≤–ª—è–µ–º –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –∑–∞–ø–∏—Å–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è—Ö
                    bibliography_entries = self._update_bibliography_with_matches(
                        bibliography_entries, validation_result
                    )
                else:
                    validation_result = {
                        'valid_references': [],
                        'missing_references': citations_result['citations'],
                        'valid_count': 0,
                        'missing_count': len(citations_result['citations']),
                        'bibliography_found': False
                    }
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è: {e}")
                validation_result = {
                    'valid_references': [],
                    'missing_references': [],
                    'valid_count': 0,
                    'missing_count': 0,
                    'bibliography_found': False
                }

            # 7. –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            print("üîç –®–∞–≥ 7: –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç...")
            try:
                analysis_result = self._format_simple_result(
                    doc_id, document, citations_result, validation_result, bibliography_entries
                )

                end_time = time.time()
                print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {end_time - start_time:.2f} —Å–µ–∫—É–Ω–¥")
                print(
                    f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç: {len(analysis_result.get('citations', []))} —Ü–∏—Ç–∞—Ç, {len(analysis_result.get('bibliography_entries', []))} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")

                self.analysis_results[doc_id] = analysis_result
                return analysis_result

            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {e}")
                import traceback
                traceback.print_exc()

                result = {
                    'doc_id': doc_id,
                    'status': 'error',
                    'citations_found': 0,
                    'issues_found': 0,
                    'bibliography_entries_found': 0,
                    'citations': [],
                    'issues': [],
                    'bibliography_entries': [],
                    'summary': {},
                    'error_message': f'–û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {str(e)}'
                }
                self.analysis_results[doc_id] = result
                return result

        except Exception as e:
            print(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –í analyze_document: {e}")
            import traceback
            traceback.print_exc()

            error_result = {
                'doc_id': doc_id,
                'status': 'error',
                'citations_found': 0,
                'issues_found': 0,
                'bibliography_entries_found': 0,
                'citations': [],
                'issues': [],
                'bibliography_entries': [],
                'summary': {},
                'error_message': str(e)
            }
            self.analysis_results[doc_id] = error_result
            return error_result

    def _verify_citation_against_source(self, citation: Dict, source: Dict) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ü–∏—Ç–∞—Ç—É –ø—Ä–æ—Ç–∏–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            source_content = library_service._load_source_content(source['id'])

            if not source_content:
                return {
                    'verified': False,
                    'confidence': 0,
                    'source_id': source['id'],
                    'source_title': source.get('title', 'Unknown'),
                    'reason': '–¢–µ–∫—Å—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω'
                }

            # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            citation_data = {
                'text': citation.get('text', ''),
                'context': citation.get('context', ''),
                'full_paragraph': citation.get('full_paragraph', ''),
                'citation_number': citation.get('citation_number')
            }

            source_data = {
                'id': source['id'],
                'title': source.get('title', ''),
                'full_content': source_content
            }

            # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
            result = self.semantic_matcher.verify_citation_in_source(
                citation_data, source_data
            )

            return {
                'verified': result['verified'],
                'confidence': result['confidence'],
                'verification_level': result.get('verification_level', 'unknown'),
                'source_id': source['id'],
                'source_title': source.get('title', 'Unknown'),
                'best_match': result.get('best_match'),
                'key_phrases_matched': result.get('best_match', {}).get('key_phrases_matched', [])
            }

        except Exception as e:
            logger.error(f"Error verifying citation against source: {e}")
            return {
                'verified': False,
                'confidence': 0,
                'source_id': source.get('id', 'unknown'),
                'source_title': source.get('title', 'Unknown'),
                'reason': f'–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}'
            }

    def _ensure_serializable(self, data: Any) -> Any:
        """–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö"""
        if data is None:
            return {}
        if isinstance(data, dict):
            return {k: self._ensure_serializable(v) for k, v in data.items()}
        if isinstance(data, list):
            return [self._ensure_serializable(item) for item in data]
        if isinstance(data, (str, int, float, bool)):
            return data
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –ª—é–±—ã–µ –¥—Ä—É–≥–∏–µ —Ç–∏–ø—ã –≤ —Å—Ç—Ä–æ–∫—É
        return str(data)

    def _create_bibliography_entries(self, bibliography_blocks: List[TextBlock]) -> List[Dict[str, Any]]:
        """–°–æ–∑–¥–∞–µ—Ç –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –∑–∞–ø–∏—Å–∏ –∫–∞–∫ –ø—Ä–æ—Å—Ç—ã–µ —Å–ª–æ–≤–∞—Ä–∏"""
        entries = []
        for i, block in enumerate(bibliography_blocks):
            entry = {
                'id': f"bib_{i}",
                'text': block.text,
                'position': {
                    'page': block.page_num,
                    'block_type': block.block_type.value
                },
                'is_valid': False,
                'is_verified': False,
                'matched_citations': [],
                'online_metadata': {},  # –ù–∞—á–∏–Ω–∞–µ–º —Å –ø—É—Å—Ç–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è
                'enhancement_confidence': 0.0,
                'search_queries': []
            }
            entries.append(entry)
        return entries

    def _update_bibliography_with_matches(self, bibliography_entries: List[Dict], validation_result: Dict) -> List[
        Dict]:
        valid_refs = set(validation_result.get('valid_references', []))

        print(f"–ü–†–û–í–ï–†–ö–ê –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø –ë–ò–ë–õ–ò–û–ì–†–ê–§–ò–ò –ò –¶–ò–¢–ê–¢")
        print(f"   –í–∞–ª–∏–¥–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã: {sorted(valid_refs)}")
        print(f"   –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏–∏: {len(bibliography_entries)}")

        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å—ã
        for entry in bibliography_entries:
            entry['matched_citations'] = []
            entry['is_valid'] = False

        # –î–ª—è –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏–∏ –±–µ–∑ —è–≤–Ω—ã—Ö –Ω–æ–º–µ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç—É—é –ª–æ–≥–∏–∫—É:
        # –ï—Å–ª–∏ –µ—Å—Ç—å N –∑–∞–ø–∏—Å–µ–π, —Ç–æ –æ–Ω–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –Ω–æ–º–µ—Ä–∞–º 1..N
        entry_number_mapping = {}
        total_entries = len(bibliography_entries)

        print(f"   –°–û–ó–î–ê–ï–ú –°–û–û–¢–í–ï–¢–°–¢–í–ò–Ø (1..{total_entries}):")
        for i in range(total_entries):
            number = str(i + 1)
            entry_number_mapping[number] = bibliography_entries[i]
            print(f"      –ù–æ–º–µ—Ä {number} -> –ó–∞–ø–∏—Å—å #{i + 1}")

        # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Ü–∏—Ç–∞—Ç—ã —Å –∑–∞–ø–∏—Å—è–º–∏
        matched_count = 0
        for ref in valid_refs:
            print(f"   –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º —Ü–∏—Ç–∞—Ç—É '[{ref}]'...")
            if ref in entry_number_mapping:
                entry = entry_number_mapping[ref]
                entry['matched_citations'].append(ref)
                entry['is_valid'] = True
                matched_count += 1
                print(f"      –¶–∏—Ç–∞—Ç–∞ [{ref}] -> –ó–∞–ø–∏—Å—å #{bibliography_entries.index(entry) + 1}")
            else:
                print(f"      –¶–∏—Ç–∞—Ç–∞ [{ref}] –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ –ø—Ä–µ–¥–µ–ª—ã –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏–∏ (1..{total_entries})")

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        valid_count = len([e for e in bibliography_entries if e['is_valid']])
        print(f"–ò–¢–û–ì: {valid_count} –∏–∑ {total_entries} –∑–∞–ø–∏—Å–µ–π –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è")

        return bibliography_entries

    def _format_simple_result(self, doc_id: str, document: ParsedDocument, citations_result: Dict,
                              validation_result: Dict, bibliography_entries: List[Dict]) -> Dict[str, Any]:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫–∞–∫ –ø—Ä–æ—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å"""

        print(f"\n{'=' * 80}")
        print("üîç –§–û–†–ú–ò–†–û–í–ê–ù–ò–ï –¶–ò–¢–ê–¢ –î–õ–Ø –§–†–û–ù–¢–ï–ù–î–ê:")

        # –ü–æ–ª—É—á–∞–µ–º details
        details_data = citations_result.get('details', [])

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ü–∏—Ç–∞—Ç—ã
        citations = []

        if isinstance(details_data, list):
            print(f"   –ù–∞–π–¥–µ–Ω–æ {len(details_data)} –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –æ —Ü–∏—Ç–∞—Ç–∞—Ö")

            for i, detail in enumerate(details_data):
                if not isinstance(detail, dict):
                    continue

                citation_num = detail.get('citation', '')

                # ====== –§–ò–õ–¨–¢–†: –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã ======
                if not citation_num.isdigit():
                    print(f"   –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ-—Ü–∏—Ñ—Ä–æ–≤—É—é —Ü–∏—Ç–∞—Ç—É: [{citation_num}]")
                    continue

                # ====== –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ —Ü–∏—Ç–∞—Ç–µ ======
                full_paragraph = detail.get('merged_paragraph', '')
                if not full_paragraph and detail.get('paragraphs'):
                    full_paragraph = detail['paragraphs'][0] if detail['paragraphs'] else ''

                # –ù–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                page_num = 1
                occurrences = detail.get('occurrences', [])
                if occurrences:
                    page_num = occurrences[0].get('page', 1)

                # ====== –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å —Ü–∏—Ç–∞—Ç–æ–π (–¥–ª—è citation.text) ======
                citation_text = f"[{citation_num}]"  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
                context_text = ""

                if full_paragraph:
                    # –ò—â–µ–º —Ü–∏—Ç–∞—Ç—É –≤ —Ç–µ–∫—Å—Ç–µ
                    citation_marker = f"[{citation_num}]"
                    if citation_marker in full_paragraph:
                        # –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é —Ü–∏—Ç–∞—Ç—ã
                        pos = full_paragraph.find(citation_marker)

                        # 1. –ù–∞—Ö–æ–¥–∏–º –Ω–∞—á–∞–ª–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–¥–ª—è citation.text)
                        sentence_start = pos
                        for j in range(pos - 1, max(-1, pos - 300), -1):
                            if j < 0:
                                sentence_start = 0
                                break
                            if full_paragraph[j] in '.!?':
                                sentence_start = j + 1
                                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
                                while sentence_start < len(full_paragraph) and full_paragraph[
                                    sentence_start] in ' \t\n':
                                    sentence_start += 1
                                break

                        # 2. –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω–µ—Ü –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
                        sentence_end = pos + len(citation_marker)
                        for j in range(sentence_end, min(len(full_paragraph), sentence_end + 300)):
                            if full_paragraph[j] in '.!?':
                                sentence_end = j + 1
                                # –í–∫–ª—é—á–∞–µ–º –∑–∞–∫—Ä—ã–≤–∞—é—â–∏–µ –∫–∞–≤—ã—á–∫–∏
                                while sentence_end < len(full_paragraph) and full_paragraph[sentence_end] in '"¬ª\u201d':
                                    sentence_end += 1
                                break

                        # 3. –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–ª–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å —Ü–∏—Ç–∞—Ç–æ–π
                        full_sentence = full_paragraph[sentence_start:sentence_end].strip()

                        if full_sentence:
                            citation_text = full_sentence
                            print(f"   –¶–∏—Ç–∞—Ç–∞ [{citation_num}]: {full_sentence[:80]}...")

                        # 4. –°–æ–∑–¥–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–¥–ª—è citation.context)
                        # –ë–µ—Ä–µ–º 100 —Å–∏–º–≤–æ–ª–æ–≤ –¥–æ –∏ –ø–æ—Å–ª–µ —Ü–∏—Ç–∞—Ç—ã
                        context_start = max(0, pos - 100)
                        context_end = min(len(full_paragraph), pos + len(citation_marker) + 100)
                        context_text = full_paragraph[context_start:context_end]

                        # –î–æ–±–∞–≤–ª—è–µ–º –º–Ω–æ–≥–æ—Ç–æ—á–∏—è –µ—Å–ª–∏ –æ–±—Ä–µ–∑–∞–ª–∏
                        if context_start > 0:
                            context_text = "..." + context_text
                        if context_end < len(full_paragraph):
                            context_text = context_text + "..."

                    else:
                        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ü–∏—Ç–∞—Ç—É –≤ —Ç–µ–∫—Å—Ç–µ, –±–µ—Ä–µ–º –Ω–∞—á–∞–ª–æ –∞–±–∑–∞—Ü–∞
                        citation_text = full_paragraph[:150] + "..." if len(full_paragraph) > 150 else full_paragraph
                        context_text = full_paragraph

                # ====== –§–æ—Ä–º–∏—Ä—É–µ–º –æ–±—ä–µ–∫—Ç —Ü–∏—Ç–∞—Ç—ã –¥–ª—è —Ñ—Ä–æ–Ω—Ç–µ–Ω–¥–∞ ======
                citations.append({
                    'id': f"cit_{len(citations)}",
                    'text': citation_text,  # –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å —Ü–∏—Ç–∞—Ç–æ–π
                    'context': context_text,  # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
                    'full_paragraph': full_paragraph,  # –ü–æ–ª–Ω—ã–π –∞–±–∑–∞—Ü
                    'page': page_num,
                    'style': 'numeric',
                    'citation_number': int(citation_num)
                })

        print(f"‚úÖ –°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–æ {len(citations)} –≤–∞–ª–∏–¥–Ω—ã—Ö —Ü–∏—Ç–∞—Ç")

        # ====== –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–±–ª–µ–º—ã ======
        issues = []

        # –ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏ (—Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä–æ–≤—ã–µ)
        valid_missing_refs = []
        for missing_ref in validation_result.get('missing_references', []):
            if isinstance(missing_ref, str) and missing_ref.isdigit():
                valid_missing_refs.append(missing_ref)
            else:
                print(f"   –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –Ω–µ-—Ü–∏—Ñ—Ä–æ–≤—É—é –ø—Ä–æ–ø—É—â–µ–Ω–Ω—É—é —Å—Å—ã–ª–∫—É: '{missing_ref}'")

        for missing_ref in valid_missing_refs:
            issue = {
                'type': 'missing',
                'description': f"–°—Å—ã–ª–∫–∞ '[{missing_ref}]' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏–∏",
                'severity': "high",
                'suggestion': "–î–æ–±–∞–≤—å—Ç–µ –∑–∞–ø–∏—Å—å –≤ —Ä–∞–∑–¥–µ–ª –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏–∏"
            }
            issues.append(issue)

        # –ù–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –∑–∞–ø–∏—Å–∏
        unused_entries = [entry for entry in bibliography_entries if not entry.get('is_valid', False)]
        for entry in unused_entries:
            issue = {
                'type': 'unused',
                'description': f"–ë–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è –∑–∞–ø–∏—Å—å –Ω–µ —Å–≤—è–∑–∞–Ω–∞ —Å —Ü–∏—Ç–∞—Ç–∞–º–∏: {entry.get('text', '')[:100]}...",
                'severity': "medium",
                'suggestion': "–£–¥–∞–ª–∏—Ç–µ –∑–∞–ø–∏—Å—å –∏–ª–∏ –¥–æ–±–∞–≤—å—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é —Ü–∏—Ç–∞—Ç—É –≤ —Ç–µ–∫—Å—Ç"
            }
            issues.append(issue)

        # ====== –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É ======
        total_citations = len(citations)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫
        valid_count = len(validation_result.get('valid_references', []))

        completeness_score = valid_count / max(1, total_citations) if total_citations > 0 else 0.0

        summary = {
            "total_references": total_citations,
            "missing_references": len(valid_missing_refs),
            "unused_references": len(unused_entries),
            "duplicate_references": 0,
            "bibliography_entries": len(bibliography_entries),
            "valid_bibliography_entries": len([e for e in bibliography_entries if e.get('is_valid', False)]),
            "completeness_score": round(completeness_score * 100, 2)  # –í –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
        }

        result = {
            'doc_id': doc_id,
            'status': 'completed',
            'citations_found': len(citations),
            'issues_found': len(issues),
            'bibliography_entries_found': len(bibliography_entries),
            'citations': citations,
            'issues': issues,
            'bibliography_entries': bibliography_entries,
            'summary': summary,
            'error_message': None
        }

        print(f"{'=' * 80}\n")
        return result

    def get_analysis_result(self, doc_id: str) -> Optional[Dict[str, Any]]:
        return self.analysis_results.get(doc_id)

    async def perform_semantic_check(self, doc_id: str) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –ø—Ä–æ–≤–µ—Ä–∫—É —Å —Ç–∞–π–º–∞—É—Ç–∞–º–∏"""
        try:
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–∞–π–º–∞—É—Ç
            timeout_seconds = 30

            # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á—É —Å —Ç–∞–π–º–∞—É—Ç–æ–º
            task = asyncio.create_task(self._perform_semantic_check_internal(doc_id))

            try:
                result = await asyncio.wait_for(task, timeout=timeout_seconds)
                return result
            except asyncio.TimeoutError:
                print(f"‚ùå –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–≤—ã—Å–∏–ª–∞ —Ç–∞–π–º–∞—É—Ç {timeout_seconds} —Å–µ–∫—É–Ω–¥")
                task.cancel()  # –û—Ç–º–µ–Ω—è–µ–º –∑–∞–¥–∞—á—É
                return {
                    'success': False,
                    'error': '–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è',
                    'doc_id': doc_id
                }

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–µ: {e}")
            import traceback
            traceback.print_exc()
            return {
                'success': False,
                'error': str(e),
                'doc_id': doc_id
            }

    async def _perform_semantic_check_internal(self, doc_id: str) -> Dict[str, Any]:
        """–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –ª–æ–≥–∏–∫–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        print(f"\nüîç –ù–ê–ß–ò–ù–ê–ï–ú –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–£–Æ –ü–†–û–í–ï–†–ö–£ –î–õ–Ø –î–û–ö–£–ú–ï–ù–¢–ê {doc_id}")

        # –ü–æ–ª—É—á–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        analysis_result = self.analysis_results.get(doc_id)
        if not analysis_result:
            return {'success': False, 'error': 'Analysis result not found'}

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
        user_id = "demo_user"

        # –ó–î–ï–°–¨ –í–ê–ñ–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å library_service
        if not hasattr(self, 'library_service') or self.library_service is None:
            return {'success': False, 'error': 'Library service not available'}

        user_sources = getattr(self.library_service, 'sources', {}).get(user_id, [])
        print(f"üìö –ü—Ä–æ–≤–µ—Ä—è–µ–º {len(analysis_result['citations'])} —Ü–∏—Ç–∞—Ç –ø—Ä–æ—Ç–∏–≤ {len(user_sources)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤")

        if not user_sources:
            return {
                'success': True,
                'doc_id': doc_id,
                'verified_citations': 0,
                'total_citations': len(analysis_result['citations']),
                'message': '–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –ø—É—Å—Ç–∞'
            }

        enhanced_citations = []
        processed_count = 0

        # –î–ª—è –∫–∞–∂–¥–æ–π —Ü–∏—Ç–∞—Ç—ã –∏—â–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö
        for citation in analysis_result['citations']:
            citation_verifications = []
            processed_count += 1

            print(f"üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–∏—Ç–∞—Ç—ã {processed_count}/{len(analysis_result['citations'])}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤ –∫–∞–∂–¥–æ–º –∏—Å—Ç–æ—á–Ω–∏–∫–µ
            for source in user_sources:
                if source.get('has_content'):
                    try:
                        verification_result = await self._verify_citation_against_source_async(
                            citation, source
                        )

                        if verification_result['verified']:
                            citation_verifications.append(verification_result)
                            # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ —É—Å–ø–µ—à–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                            break
                    except Exception as e:
                        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ {source.get('id')}: {e}")
                        continue

            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫ —Ü–∏—Ç–∞—Ç–µ
            citation['semantic_verifications'] = citation_verifications
            citation['verified_count'] = len(citation_verifications)
            citation['is_verified'] = len(citation_verifications) > 0

            enhanced_citations.append(citation)

        # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        analysis_result['citations'] = enhanced_citations

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        verified_citations = [c for c in enhanced_citations if c.get('is_verified')]
        analysis_result['semantic_verification_stats'] = {
            'total_citations': len(enhanced_citations),
            'verified_citations': len(verified_citations),
            'verification_rate': len(verified_citations) / len(enhanced_citations) if enhanced_citations else 0,
            'sources_checked': len(user_sources),
            'status': 'completed'
        }
        analysis_result['semantic_check_pending'] = False

        print(
            f"‚úÖ –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(verified_citations)} –∏–∑ {len(enhanced_citations)} —Ü–∏—Ç–∞—Ç –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω—ã"
        )

        return {
            'success': True,
            'doc_id': doc_id,
            'verified_citations': len(verified_citations),
            'total_citations': len(enhanced_citations)
        }