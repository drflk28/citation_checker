from typing import List, Dict, Any, Optional
from app.models.data_models import TextBlock, BibliographyEntry
import re
import requests
import time
from urllib.parse import quote
import json
from app.search.online_searcher import OnlineSearcher, SearchResult
from app.config import APIConfig
from app.search.russian_sources import RussianSourcesSearcher

class BibliographyChecker:
    def __init__(self):
        self.biblio_keywords = [
            '—Å–ø–∏—Å–æ–∫ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤', '—Å–ø–∏—Å–æ–∫ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã', '–±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—è',
            '–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞', '–∏—Å—Ç–æ—á–Ω–∏–∫–∏', 'references', 'bibliography',
            'reference', 'source', 'works cited', 'literature'
        ]
        self.section_end_keywords = ['–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', 'appendix', '–∑–∞–∫–ª—é—á–µ–Ω–∏–µ', 'conclusion']

        self.search_apis = {
            'google_books': 'https://www.googleapis.com/books/v1/volumes',
            'crossref': 'https://api.crossref.org/works',
            'open_library': 'https://openlibrary.org/search.json',
            'semantic_scholar': 'https://api.semanticscholar.org/graph/v1/paper/search'
        }
        self.searcher = OnlineSearcher(APIConfig())
        self.russian_searcher = RussianSourcesSearcher()

    def find_bibliography_section(self, text_blocks: List[TextBlock]) -> List[TextBlock]:
        print("–ü–æ–∏—Å–∫ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏–∏...")
        bibliography_blocks = []
        in_bibliography = False
        found_header = False
        non_biblio_count = 0

        for block in text_blocks:
            text = block.text.strip()
            text_lower = text.lower()

            if (not found_header and
                    any(keyword in text_lower for keyword in self.biblio_keywords) and
                    '...' not in text and
                    len(text) < 100):
                print(f"–ù–∞–π–¥–µ–Ω —Ä–µ–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏–∏: '{text}'")
                in_bibliography = True
                found_header = True
                continue

            if in_bibliography:
                if self._is_bibliography_entry(text):
                    bibliography_blocks.append(block)
                    non_biblio_count = 0
                    print(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∞—è –∑–∞–ø–∏—Å—å: {text[:60]}...")
                else:
                    non_biblio_count += 1
                    if non_biblio_count >= 3:
                        print(f"‚Ñπ –û–±–Ω–∞—Ä—É–∂–µ–Ω –∫–æ–Ω–µ—Ü –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏–∏ (–ø–æ–¥—Ä—è–¥ {non_biblio_count} –Ω–µ-–±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –±–ª–æ–∫–æ–≤)")
                        break
                    if self._is_definitely_not_bibliography(text):
                        print(f"‚Ñπ –û–±–Ω–∞—Ä—É–∂–µ–Ω —è–≤–Ω–æ –Ω–µ-–±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π –±–ª–æ–∫: {text[:50]}...")
                        break
                    if self._looks_like_table_data(text):
                        print(f"‚Ñπ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ —Ç–∞–±–ª–∏—Ü—ã: {text[:50]}...")
                        break

        print(f"–ù–∞–π–¥–µ–Ω–æ –∑–∞–ø–∏—Å–µ–π –≤ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏–∏: {len(bibliography_blocks)}")
        return bibliography_blocks

    def enhance_with_online_search(self, bibliography_entries: List[BibliographyEntry]) -> List[BibliographyEntry]:
        """–£–ª—É—á—à–∞–µ—Ç –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –∑–∞–ø–∏—Å–∏ —Å –ø–æ–º–æ—â—å—é –æ–Ω–ª–∞–π–Ω-–ø–æ–∏—Å–∫–∞"""
        print("–£–ª—É—á—à–∞–µ–º –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –∑–∞–ø–∏—Å–∏ –æ–Ω–ª–∞–π–Ω-–ø–æ–∏—Å–∫–æ–º...")

        enhanced_entries = []

        for i, entry in enumerate(bibliography_entries):
            print(f"   –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø–∏—Å—å {i + 1}/{len(bibliography_entries)}: {entry.text[:50]}...")

            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            search_queries = self._generate_search_queries(entry.text)
            entry.search_queries = search_queries

            best_result = None

            # —Å–Ω–∞—á–∞–ª–∞ —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            russian_result = self.russian_searcher.search_publication(
                search_queries[0] if search_queries else entry.text,
                entry.text
            )

            if russian_result:
                best_result = self._convert_russian_result_to_search_result(russian_result)
                print(f"      –ù–∞–π–¥–µ–Ω –≤ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {best_result.confidence:.2f})")
            else:
                # –µ—Å–ª–∏ –Ω–µ —Ä–æ—Å —Ç–æ –º–µ–∂–¥—É–Ω–∞—Ä
                for query in search_queries:
                    print(f"      –ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–π –ø–æ–∏—Å–∫: '{query}'")
                    results = self.searcher.search_publication(query)

                    if results:
                        # –§–∏–ª—å—Ç—Ä—É–µ–º –∏ –≤—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        relevant_results = [r for r in results if self._is_relevant_result(r, entry.text)]
                        if relevant_results:
                            best_result = self._filter_best_result(relevant_results, entry.text)
                            if best_result:
                                print(f"      –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {best_result.confidence:.2f})")
                                break
                        else:
                            print(f"      –ù–∞–π–¥–µ–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –Ω–æ –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ")
                    else:
                        print(f"      –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ—Ç")

            if best_result:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º SearchResult –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è online_metadata
                entry.online_metadata = {
                    'source': best_result.source,
                    'title': best_result.title,
                    'authors': best_result.authors or [],
                    'year': best_result.year,
                    'publisher': best_result.publisher,
                    'journal': best_result.journal,
                    'volume': best_result.volume,
                    'issue': best_result.issue,
                    'pages': best_result.pages,
                    'doi': best_result.doi,
                    'isbn': best_result.isbn,
                    'url': best_result.url,
                    'confidence': best_result.confidence,
                    'retrieved_at': time.time(),
                    #'description': getattr(best_result, 'description', '')
                }
                entry.enhancement_confidence = best_result.confidence
                entry.is_verified = True
                print(f"      –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é: {best_result.confidence:.2f}")
            else:
                # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ online_metadata —ç—Ç–æ –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å, –∞ –Ω–µ None
                entry.online_metadata = {}
                print(f"      –ü–æ–¥—Ö–æ–¥—è—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")

            enhanced_entries.append(entry)

        print(
            f"–£–ª—É—á—à–µ–Ω–æ {len([e for e in enhanced_entries if e.online_metadata])} –∏–∑ {len(enhanced_entries)} –∑–∞–ø–∏—Å–µ–π")
        return enhanced_entries

    def _convert_russian_result_to_search_result(self, russian_result: Dict[str, Any]) -> SearchResult:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ SearchResult"""
        url = russian_result.get('record_url') or russian_result.get('url')

        return SearchResult(
            source=russian_result['source'],
            title=russian_result.get('title', ''),
            authors=russian_result.get('authors', []),
            year=russian_result.get('year'),
            publisher=russian_result.get('publisher'),
            journal=russian_result.get('journal'),
            volume=None,
            issue=None,
            pages=None,
            doi=None,
            isbn=None,
            url=url,
            confidence=russian_result.get('confidence', 0.6),
            is_search_link=russian_result.get('is_search_link', False)
        )

    def _enhance_single_entry(self, entry: BibliographyEntry) -> BibliographyEntry:
        """–£–ª—É—á—à–∞–µ—Ç –æ–¥–Ω—É –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫—É—é –∑–∞–ø–∏—Å—å"""
        search_queries = self._generate_search_queries(entry.text)
        entry.search_queries = search_queries

        best_overall_result = None
        best_confidence = 0.0

        for query in search_queries:
            print(f"      –ü–æ–∏—Å–∫: '{query}'")
            try:
                results = self.online_searcher.search_publication(query)

                if results:
                    best_result = self._filter_best_result(results, query)

                    if best_result and best_result.confidence > best_confidence:
                        best_overall_result = best_result
                        best_confidence = best_result.confidence
                        print(f"      –ù–∞–π–¥–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {best_result.confidence:.2f})")

                        if best_result.confidence > 0.8:
                            break
                else:
                    print(f"      –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è: {query}")

            except Exception as e:
                print(f"      –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ '{query}': {e}")
                continue

        if best_overall_result and best_confidence > 0.3:
            entry.online_metadata = self._format_online_metadata(best_overall_result)
            entry.is_verified = True
            entry.enhancement_confidence = best_confidence
            print(f"      –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é: {best_confidence:.2f}")
        else:
            print(f"      –ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

        return entry

    def _format_online_metadata(self, result: SearchResult) -> Dict[str, Any]:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è"""
        return {
            'source': result.source,
            'title': result.title,
            'authors': result.authors,
            'year': result.year,
            'publisher': result.publisher,
            'journal': result.journal,
            'volume': result.volume,
            'issue': result.issue,
            'pages': result.pages,
            'doi': result.doi,
            'isbn': result.isbn,
            'url': result.url,
            'confidence': result.confidence,
            'retrieved_at': time.time()
        }

    def _generate_search_queries(self, text: str) -> List[str]:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–∏—Å–∫–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        queries = []

        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
        clean_text = re.sub(r'\[.*?\]', '', text)
        clean_text = re.sub(r'[^\w\s.,;:()-]', '', clean_text)

        # 1. –û—Å–Ω–æ–≤–Ω–æ–π –æ—á–∏—â–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        if clean_text.strip():
            queries.append(clean_text.strip())

        # 2. –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å
        simple_text = re.sub(
            r'\b(–∏–∑–¥-–≤–æ|–∏–∑–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ|—É—á–µ–±–Ω–∏–∫|–ø–æ—Å–æ–±–∏–µ|–º–æ–Ω–æ–≥—Ä–∞—Ñ–∏—è|—Å—Ç–∞—Ç—å—è|–ø–æ–¥ —Ä–µ–¥|—Ä–µ–¥\.|—Å\.|—Å—Ç—Ä\.|—Ç\.|–≤—ã–ø\.)\b.*?[.,]', '',
            clean_text, flags=re.IGNORECASE)
        simple_text = re.sub(r'\d+\.\d+|\d+-\d+', '', simple_text)  # –£–±–∏—Ä–∞–µ–º –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü
        if simple_text.strip() and simple_text != clean_text:
            queries.append(simple_text.strip())

        # 3. –ó–∞–ø—Ä–æ—Å —Å –∞–≤—Ç–æ—Ä–∞–º–∏ –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ–º
        authors = self._extract_authors(clean_text)
        title = self._extract_title(clean_text)
        if authors and title:
            queries.append(f"{authors} {title}")

        # 4. –ó–∞–ø—Ä–æ—Å —Ç–æ–ª—å–∫–æ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º
        improved_title = self._extract_improved_title(clean_text)
        if improved_title:
            queries.append(improved_title)

        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã
        unique_queries = []
        seen = set()
        for query in queries:
            if query and len(query) > 10 and query not in seen:
                seen.add(query)
                unique_queries.append(query)

        return unique_queries[:4]

    def _extract_improved_title(self, text: str) -> Optional[str]:
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ä–∞–±–æ—Ç—ã"""
        # –£–±–∏—Ä–∞–µ–º –∞–≤—Ç–æ—Ä–æ–≤ (–≤—Å—ë –¥–æ –ø–µ—Ä–≤–æ–π —Ç–æ—á–∫–∏ –∏–ª–∏ –¥–≤–æ–µ—Ç–æ—á–∏—è)
        text_without_authors = re.sub(r'^[^.:]*[.:]', '', text).strip()

        # –£–±–∏—Ä–∞–µ–º –≥–æ–¥
        text_without_year = re.sub(r'\b(19|20)\d{2}\b', '', text_without_authors)

        # –£–±–∏—Ä–∞–µ–º –∏–∑–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ –∏ –ø—Ä–æ—á—É—é —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        patterns_to_remove = [
            r'\/\/.*$',  # –í—Å—ë –ø–æ—Å–ª–µ //
            r'‚Äî.*$',  # –í—Å—ë –ø–æ—Å–ª–µ ‚Äî
            r'\.‚Äî.*$',  # –í—Å—ë –ø–æ—Å–ª–µ .‚Äî
            r'\(.*\)',  # –°–∫–æ–±–∫–∏ —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º
            r'\b(–∏–∑–¥-–≤–æ|–∏–∑–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ|—É—á–µ–±–Ω–∏–∫|–ø–æ—Å–æ–±–∏–µ|–º–æ–Ω–æ–≥—Ä–∞—Ñ–∏—è|—Å—Ç–∞—Ç—å—è)\b.*$',
        ]

        for pattern in patterns_to_remove:
            text_without_year = re.sub(pattern, '', text_without_year)

        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 5-8 —Å–ª–æ–≤ –∫–∞–∫ –≤–æ–∑–º–æ–∂–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        words = text_without_year.strip().split()
        if len(words) > 2:
            return ' '.join(words[:min(8, len(words))])

        return None

    def _extract_authors(self, text: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞–≤—Ç–æ—Ä–æ–≤ –∏–∑ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–π –∑–∞–ø–∏—Å–∏"""
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ä—É—Å—Å–∫–∏—Ö –∞–≤—Ç–æ—Ä–æ–≤: "–ò–≤–∞–Ω–æ–≤ –ò.–ò.", "–ü–µ—Ç—Ä–æ–≤ –ê.–í."
        patterns = [
            r'^([–ê-–Ø][–∞-—è]+ [–ê-–Ø]\.[–ê-–Ø]\.)',  # –ò–≤–∞–Ω–æ–≤ –ò.–ò.
            r'^([–ê-–Ø][–∞-—è]+ [–ê-–Ø][–∞-—è]+ [–ê-–Ø]\.[–ê-–Ø]\.)',  # –ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò.–ò.
            r'^([–ê-–Ø][–∞-—è]+,\s*[–ê-–Ø]\.[–ê-–Ø]\.)',  # –ò–≤–∞–Ω–æ–≤, –ò.–ò.
        ]

        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                return match.group(1)

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –∞–≤—Ç–æ—Ä–æ–≤
        patterns_en = [
            r'^([A-Z][a-z]+ [A-Z]\.)',  # Smith J.
            r'^([A-Z][a-z]+ [A-Z]\. [A-Z]\.)',  # Smith J. K.
            r'^([A-Z][a-z]+,\s*[A-Z]\.)',  # Smith, J.
        ]

        for pattern in patterns_en:
            match = re.search(pattern, text)
            if match:
                return match.group(1)

        return None

    def _extract_year(self, text: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≥–æ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""
        match = re.search(r'\b(19|20)\d{2}\b', text)
        return match.group(0) if match else None

    def _extract_title(self, text: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç—ã"""
        # –£–±–∏—Ä–∞–µ–º –∞–≤—Ç–æ—Ä–æ–≤ –∏ –≥–æ–¥, –æ—Å—Ç–∞–≤—à–µ–µ—Å—è - –≤–µ—Ä–æ—è—Ç–Ω–æ –Ω–∞–∑–≤–∞–Ω–∏–µ
        text_without_authors = re.sub(r'^[^.]*\.', '', text)  # –£–±–∏—Ä–∞–µ–º —á–∞—Å—Ç—å –¥–æ –ø–µ—Ä–≤–æ–π —Ç–æ—á–∫–∏
        text_without_year = re.sub(r'\b(19|20)\d{2}\b', '', text_without_authors)

        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 5-10 —Å–ª–æ–≤ –∫–∞–∫ –≤–æ–∑–º–æ–∂–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        words = text_without_year.strip().split()
        if len(words) > 3:
            return ' '.join(words[:min(8, len(words))])

        return None


    def _is_definitely_not_bibliography(self, text: str) -> bool:
        text_lower = text.lower()
        not_biblio_indicators = [
            any(word in text_lower for word in ['—Ç.—Ä.', '—Ç—ã—Å. —Ä—É–±.', '—Ä—É–±.', '—Å—Ç–æ–∏–º–æ—Å—Ç—å', '—Ü–µ–Ω–∞', '–∑–∞–∫—É–ø–∫–∞']),
            re.search(r'\d+\s*—Ç\.—Ä\.', text),
            re.search(r'\d+\s*—Ä—É–±', text),
            any(term in text_lower for term in ['–Ω–¥—Å', '–æ–±–æ—Ä—É–¥–æ–≤–∞–Ω', '–ø–µ—Ä—Å–æ–Ω–∞–ª', '–ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤']),
            len(text) < 30 and any(char.isdigit() for char in text),
            any(char in text for char in ['+', '-', '*', '/', '=']),
        ]
        return any(not_biblio_indicators)

    def _looks_like_table_data(self, text: str) -> bool:
        table_indicators = [
            bool(re.search(r'\d+[\s,]*—Ç\.—Ä\.', text)),
            bool(re.search(r'\d+[\s,]*—Ä—É–±', text)),
            bool(re.search(r'\d+[\s,]*%', text)),
            len(text) < 50 and any(char.isdigit() for char in text),
            any(word in text.lower() for word in ['—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å', '–∑–∞–∫—É–ø–∫–∞', '—Ä–∞—Å—Ö–æ–¥', '–¥–æ—Ö–æ–¥']),
        ]
        return any(table_indicators)

    def _is_bibliography_entry(self, text: str) -> bool:
        if not text or not text.strip():
            return False

        text_lower = text.lower().strip()

        if any(keyword in text_lower for keyword in self.biblio_keywords):
            return False
        if '...' in text:
            return False
        if len(text) < 20:
            return False

        starts_with_number = any(text.strip().startswith(f"{i}.") for i in range(1, 100))
        starts_with_bracket = re.match(r'^\[\d+\]', text.strip())
        has_year = bool(re.search(r'\b(19|20)\d{2}\b', text))

        has_biblio_keywords = any(keyword in text_lower for keyword in [
            '–∏–∑–¥-–≤–æ', '–∏–∑–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ', '–∂—É—Ä–Ω–∞–ª', '—Ç.', '–≤—ã–ø.', '—Å.', '—Å—Ç—Ä.', '—Å—Å.',
            '—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', '—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞', '–∏–Ω—Å—Ç–∏—Ç—É—Ç', '–∞–∫–∞–¥–µ–º–∏—è', '–Ω–∞—É–∫',
            '–∏–∑–¥–∞–Ω–∏–µ', '–º–æ–Ω–æ–≥—Ä–∞—Ñ–∏—è', '—É—á–µ–±–Ω–∏–∫', '–ø–æ—Å–æ–±–∏–µ', '—Å—Ç–∞—Ç—å—è',
            '–º.:', '—Å–ø–±.:', '–∫–∏–µ–≤:', '–º–∏–Ω—Å–∫:',
            '—ç–∫–æ–Ω–æ–º–∏–∫–∞', '—Ñ–∏–Ω–∞–Ω—Å—ã', '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞', '–º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç', '–º–∞—Ä–∫–µ—Ç–∏–Ω–≥'
        ])

        has_comma_and_year = (',' in text and bool(re.search(r'\b(19|20)\d{2}\b', text)))
        punctuation_count = text.count('.') + text.count(',')
        has_punctuation = punctuation_count >= 3
        has_abbreviations = any(abbr in text for abbr in ['—Ç.', '–≤—ã–ø.', '—Å.', '—Å—Å.', '–≥.'])
        reasonable_length = 30 < len(text) < 800

        strong_indicators = [
            starts_with_number,
            bool(starts_with_bracket),
            has_year and has_punctuation,
            has_biblio_keywords and has_year,
            has_comma_and_year and has_punctuation
        ]

        weak_indicators = [
            has_year,
            has_biblio_keywords,
            has_punctuation,
            has_abbreviations
        ]

        is_bibliography = (any(strong_indicators) or (sum(weak_indicators) >= 2)) and reasonable_length

        if is_bibliography and (starts_with_number or starts_with_bracket):
            print(f"   –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ –∫–∞–∫ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—è: {text[:70]}...")

        return is_bibliography

    def check_citations_vs_bibliography(self, citations: List[str], bibliography_blocks: List[TextBlock]) -> Dict[
        str, Any]:
        if not bibliography_blocks:
            return {
                'valid_references': [],
                'missing_references': citations,
                'valid_count': 0,
                'missing_count': len(citations),
                'bibliography_found': False
            }

        bibliography_entries_count = len(bibliography_blocks)
        print(f"–ë–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—è —Å–æ–¥–µ—Ä–∂–∏—Ç {bibliography_entries_count} –∑–∞–ø–∏—Å–µ–π")

        valid_references = []
        missing_references = []

        for citation in citations:
            try:
                citation_num = int(citation)
                if 1 <= citation_num <= bibliography_entries_count:
                    valid_references.append(citation)
                    print(f"   –¶–∏—Ç–∞—Ç–∞ [{citation}] –≤–∞–ª–∏–¥–Ω–∞ (–≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 1..{bibliography_entries_count})")
                else:
                    missing_references.append(citation)
                    print(f"   –¶–∏—Ç–∞—Ç–∞ [{citation}] –≤–Ω–µ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏–∏ (1..{bibliography_entries_count})")
            except ValueError:
                missing_references.append(citation)
                print(f"   –ù–µ—á–∏—Å–ª–æ–≤–∞—è —Ü–∏—Ç–∞—Ç–∞ [{citation}] –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è")

        return {
            'valid_references': valid_references,
            'missing_references': missing_references,
            'valid_count': len(valid_references),
            'missing_count': len(missing_references),
            'bibliography_found': True
        }

    def _search_semantic_scholar(self, query: str) -> List[SearchResult]:
        """–ü–æ–∏—Å–∫ –≤ Semantic Scholar API"""
        try:
            headers = {}
            if self.config.SEMANTIC_SCHOLAR_API_KEY:
                headers['x-api-key'] = self.config.SEMANTIC_SCHOLAR_API_KEY

            params = {
                'query': query,
                'limit': 3,
                'fields': 'title,authors,year,venue,doi,url'
            }

            response = self.session.get(
                'https://api.semanticscholar.org/graph/v1/paper/search',
                params=params,
                headers=headers,
                timeout=self.config.REQUEST_TIMEOUT
            )

            if response.status_code == 200:
                data = response.json()
                return self._parse_semantic_scholar_results(data)
            else:
                self.logger.warning(f"Semantic Scholar API returned status {response.status_code}")

        except Exception as e:
            self.logger.error(f"Semantic Scholar API error: {e}")

        return []

    def _filter_best_result(self, results: List[SearchResult], original_query: str) -> Optional[SearchResult]:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É"""
        if not results:
            return None

        # –°–Ω–∞—á–∞–ª–∞ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        sorted_results = sorted(results, key=lambda x: x.confidence, reverse=True)

        # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É
        query_words = set(original_query.lower().split())

        for result in sorted_results:
            if result.title:
                title_words = set(result.title.lower().split())
                # –ï—Å–ª–∏ –µ—Å—Ç—å –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤, —Å—á–∏—Ç–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º
                common_words = query_words.intersection(title_words)
                if len(common_words) >= 2:  # –ú–∏–Ω–∏–º—É–º 2 –æ–±—â–∏—Ö —Å–ª–æ–≤–∞
                    return result

        # –ï—Å–ª–∏ –Ω–µ—Ç —è–≤–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–∞–º—ã–π —É–≤–µ—Ä–µ–Ω–Ω—ã–π
        return sorted_results[0] if sorted_results else None

    def _is_relevant_result(self, result: SearchResult, original_text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–π –∑–∞–ø–∏—Å–∏"""
        original_lower = original_text.lower()
        result_title = result.title.lower() if result.title else ""

        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –∑–∞–ø–∏—Å–∏ —Ç–µ—Å—Ç
        key_phrases = [
            '—Ç–æ–ª—Å—Ç–æ–π', '–≤–æ–π–Ω–∞ –∏ –º–∏—Ä',  # –î–ª—è –¢–æ–ª—Å—Ç–æ–≥–æ
            '—ç–∫–æ–Ω–æ–º–∏–∫', '–∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö',  # –î–ª—è —ç–∫–æ–Ω–æ–º–∏–∫–∏
            '–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ', '–∫–Ω—É—Ç—Å–µ–Ω',  # –î–ª—è ML
            '–±–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω', '–ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å—Å—Ç–≤–æ'  # –î–ª—è –±–∏–∑–Ω–µ—Å–∞
        ]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ñ—Ä–∞–∑
        for phrase in key_phrases:
            if phrase in original_lower and phrase in result_title:
                return True

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–≤—Ç–æ—Ä–æ–≤
        if result.authors:
            for author in result.authors:
                author_lower = author.lower()
                if any(author_word in original_lower for author_word in author_lower.split()):
                    return True

        return False

    def _enhance_single_entry(self, entry: BibliographyEntry) -> BibliographyEntry:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏"""
        search_queries = self._generate_search_queries(entry.text)

        if entry.online_metadata is None:
            entry.online_metadata = {}
        entry.online_metadata['search_queries_used'] = search_queries

        best_relevant_result = None
        best_confidence = 0.0

        for query in search_queries:
            print(f"      üîé –ü–æ–∏—Å–∫: '{query}'")
            try:
                results = self.online_searcher.search_publication(query)

                if results:
                    for result in results:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                        if self._is_relevant_result(result, entry.text):
                            if result.confidence > best_confidence:
                                best_relevant_result = result
                                best_confidence = result.confidence
                                print(f"      –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result.confidence:.2f})")

                                if result.confidence > 0.8:
                                    break
                    else:
                        print(f"      –ù–∞–π–¥–µ–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –Ω–æ –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ")
                else:
                    print(f"      –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è: {query}")

            except Exception as e:
                print(f"      –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ '{query}': {e}")
                continue

        if best_relevant_result and best_confidence > 0.3:
            entry.online_metadata = self._format_online_metadata(best_relevant_result)
            entry.is_verified = True
            entry.enhancement_confidence = best_confidence
            print(f"      –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é: {best_confidence:.2f}")
        else:
            print(f"      –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            # –ú–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ –∏–¥–µ–∞–ª—å–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π
            if results and not best_relevant_result:
                fallback_result = results[0]
                entry.online_metadata = self._format_online_metadata(fallback_result)
                entry.is_verified = False  # –ü–æ–º–µ—á–∞–µ–º –∫–∞–∫ –Ω–µ–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–π
                entry.enhancement_confidence = fallback_result.confidence * 0.5  # –ü–æ–Ω–∏–∂–∞–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                print(f"      –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {fallback_result.confidence:.2f})")

        return entry