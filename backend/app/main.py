import os
import shutil
import platform
import logging
import uuid
import sys
import os
import asyncio
from datetime import datetime
from typing import List, Optional

from fastapi import FastAPI, UploadFile, File, HTTPException, BackgroundTasks, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, FileResponse
sys.path.append(os.path.join(os.path.dirname(__file__), '../../app'))
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from .auth.dependencies import get_current_user, get_current_user_optional
from .services.library_service import library_service
from .models.user_models import User
from app.citation_parser.citation_extractor import CitationExtractor
from app.bibliography.checker import BibliographyChecker
from app.services.simple_analysis_service import SimpleAnalysisService
from app.services.library_service import library_service

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
from enum import Enum
from pydantic import BaseModel

# –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def check_dependencies():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    print("=" * 50)
    print("üîç –ü–†–û–í–ï–†–ö–ê –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô")
    print("=" * 50)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ PyMuPDF (fitz)
    try:
        import fitz
        print("‚úÖ PyMuPDF (fitz) - OK")
    except ImportError:
        print("‚ùå PyMuPDF (fitz) - –ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù")
        print("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install PyMuPDF")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Tesseract
    tesseract_available = shutil.which("tesseract") is not None
    if tesseract_available:
        print("‚úÖ Tesseract - OK")
    else:
        print("‚ùå Tesseract - –ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù")
        print("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–∞")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ pytesseract
    try:
        import pytesseract
        print("‚úÖ pytesseract - OK")
    except ImportError:
        print("‚ùå pytesseract - –ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù")
        print("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install pytesseract")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Pillow
    try:
        from PIL import Image
        print("‚úÖ Pillow - OK")
    except ImportError:
        print("‚ùå Pillow - –ù–ï –£–°–¢–ê–ù–û–í–õ–ï–ù")
        print("   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install pillow")

    print("=" * 50)

check_dependencies()

# –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
def clear_all_data():
    uploads_dir = "uploads"
    if os.path.exists(uploads_dir):
        shutil.rmtree(uploads_dir)
    os.makedirs(uploads_dir, exist_ok=True)
    print("–≤—Å–µ –¥–∞–Ω–Ω—ã–µ –æ—á–∏—â–µ–Ω—ã")

clear_all_data()

app = FastAPI(title="Citation Checker API", version="1.0.0")

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class AnalysisStatus(str, Enum):
    PROCESSING = "processing"
    COMPLETED = "completed"
    ERROR = "error"

class DocumentMetadata(BaseModel):
    id: str
    filename: str
    file_path: str
    file_size: int
    upload_date: str

class Citation(BaseModel):
    id: str
    text: str
    context: str
    style: Optional[str] = None

class Issue(BaseModel):
    type: str
    description: str
    severity: str
    suggestion: Optional[str] = None

class BibliographyEntry(BaseModel):
    id: str
    text: str

class Summary(BaseModel):
    total_references: int
    missing_references: int
    bibliography_entries: int
    completeness_score: float

class AnalysisResult(BaseModel):
    doc_id: str
    status: AnalysisStatus
    citations_found: Optional[int] = 0
    issues_found: Optional[int] = 0
    bibliography_entries_found: Optional[int] = 0
    citations: Optional[List[Citation]] = None
    issues: Optional[List[Issue]] = None
    bibliography_entries: Optional[List[BibliographyEntry]] = None
    summary: Optional[Summary] = None
    error_message: Optional[str] = None

# –•—Ä–∞–Ω–∏–ª–∏—â–∞ –¥–∞–Ω–Ω—ã—Ö
documents_store = {}
analysis_results = {}
analysis_status = {}

print(f"–•—Ä–∞–Ω–∏–ª–∏—â–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã: documents_store={len(documents_store)}")

class TextBlock:
    def __init__(self, text: str, page_num: int = 1, block_type: str = "paragraph"):
        self.text = text
        self.page_num = page_num
        self.block_type = block_type

# –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
analysis_service = SimpleAnalysisService()
@app.get("/")
async def root():
    return {"message": "Citation Checker API", "version": "1.0.0"}


@app.put("/api/library/sources/{source_id}")
async def update_source(source_id: str, update_data: dict):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–µ"""
    try:
        user_id = "demo_user"

        # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –∏—Å—Ç–æ—á–Ω–∏–∫
        result = await library_service.get_source_details(user_id, source_id)
        if not result["success"]:
            raise HTTPException(status_code=404, detail="–ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω")

        source = result["source"]

        # –û–±–Ω–æ–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–µ –ø–æ–ª—è
        allowed_fields = ['title', 'authors', 'year', 'source_type',
                          'journal', 'publisher', 'url', 'doi', 'isbn',
                          'custom_citation', 'tags']

        updated = False
        for field in allowed_fields:
            if field in update_data:
                source[field] = update_data[field]
                updated = True

        if updated:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
            if user_id in library_service.sources:
                for i, s in enumerate(library_service.sources[user_id]):
                    if s['id'] == source_id:
                        library_service.sources[user_id][i] = source
                        break

                library_service._save_sources()

        return {
            "success": True,
            "message": "–ò—Å—Ç–æ—á–Ω–∏–∫ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω",
            "source": source
        }

    except Exception as e:
        logger.error(f"Error updating source: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/library/sources/check-duplicate")
async def check_duplicate_source(check_data: dict):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ç–∞–∫–æ–π –∏—Å—Ç–æ—á–Ω–∏–∫ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ"""
    try:
        user_id = "demo_user"
        user_sources = library_service.sources.get(user_id, [])

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ —Ä–∞–∑–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º
        title = check_data.get('title', '').lower().strip()
        authors = check_data.get('authors', [])
        year = check_data.get('year')

        duplicates = []
        for source in user_sources:
            match_score = 0

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è
            if title and source.get('title', '').lower().strip() == title:
                match_score += 3

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–≤—Ç–æ—Ä–æ–≤
            source_authors = [a.lower() for a in source.get('authors', [])]
            check_authors = [a.lower() for a in authors]
            common_authors = set(source_authors) & set(check_authors)
            if common_authors:
                match_score += len(common_authors)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ–¥–∞
            if year and str(source.get('year')) == str(year):
                match_score += 1

            if match_score >= 2:  # –ü–æ—Ä–æ–≥ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
                duplicates.append({
                    "id": source['id'],
                    "title": source.get('title'),
                    "authors": source.get('authors', []),
                    "year": source.get('year'),
                    "match_score": match_score
                })

        return {
            "success": True,
            "has_duplicates": len(duplicates) > 0,
            "duplicates": duplicates[:5]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        }

    except Exception as e:
        logger.error(f"Error checking duplicates: {e}")
        return {
            "success": False,
            "error": str(e)
        }

@app.post("/upload", response_model=DocumentMetadata)
async def upload_document(file: UploadFile = File(...)):
    logger.info(f"Upload request for file: {file.filename}")

    if not file.filename:
        raise HTTPException(status_code=400, detail="No file provided")

    allowed_extensions = {'.pdf', '.docx', '.doc', '.txt'}
    file_extension = os.path.splitext(file.filename)[1].lower()
    if file_extension not in allowed_extensions:
        raise HTTPException(status_code=400, detail="Unsupported file type")

    doc_id = str(uuid.uuid4())
    file_path = f"uploads/{doc_id}{file_extension}"

    try:
        content = await file.read()
        with open(file_path, "wb") as buffer:
            buffer.write(content)
        logger.info(f"File saved: {file_path} ({len(content)} bytes)")
    except Exception as e:
        logger.error(f"File save error: {e}")
        raise HTTPException(status_code=500, detail="File save failed")

    metadata = DocumentMetadata(
        id=doc_id,
        filename=file.filename,
        file_path=file_path,
        file_size=len(content),
        upload_date=datetime.now().isoformat()
    )

    documents_store[doc_id] = metadata
    analysis_status[doc_id] = AnalysisStatus.PROCESSING

    logger.info(f"Document stored: {doc_id}")
    return metadata

# —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –¥–æ–∫–æ–≤
@app.get("/documents", response_model=List[DocumentMetadata])
async def list_documents():
    logger.info(f"Returning {len(documents_store)} documents")
    return list(documents_store.values())

# –∞–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
@app.post("/documents/{doc_id}/analyze")
async def analyze_document(doc_id: str):
    # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ (–∫–æ—Ç–æ—Ä–æ–µ —è–≤–ª—è–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä–µ–º)
    document = documents_store.get(doc_id)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º .get() –¥–ª—è —Å–ª–æ–≤–∞—Ä—è
    if not document:
        raise HTTPException(status_code=404, detail="Document not found")

    file_path = document.file_path  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞—Ç—Ä–∏–±—É—Ç, –∞ –Ω–µ –∫–ª—é—á —Å–ª–æ–≤–∞—Ä—è
    result = analysis_service.analyze_document(file_path, doc_id)

    return result

@app.get("/documents/{doc_id}/analysis")
async def get_analysis(doc_id: str):
    result = analysis_service.get_analysis_result(doc_id)
    if not result:
        raise HTTPException(status_code=404, detail="Analysis not found")

    return result

# —Ñ–æ–Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞ –∞–Ω–∞–ª–∏–∑–∞
async def run_analysis(doc_id: str):
    logger.info(f"Starting analysis for: {doc_id}")

    try:
        doc_metadata = documents_store[doc_id]

        analysis_result = analysis_service.analyze_document(doc_metadata.file_path, doc_id)

        analysis_results[doc_id] = analysis_result
        analysis_status[doc_id] = AnalysisStatus.COMPLETED

        logger.info(f"‚úÖ Analysis completed for: {doc_id}")

    except Exception as e:
        logger.error(f"‚ùå Analysis failed: {e}")
        error_result = AnalysisResult(
            doc_id=doc_id,
            status=AnalysisStatus.ERROR,
            error_message=str(e),
            citations=[],
            issues=[],
            bibliography_entries=[],
            summary=Summary(
                total_references=0,
                missing_references=0,
                bibliography_entries=0,
                completeness_score=0.0
            )
        )
        analysis_results[doc_id] = error_result
        analysis_status[doc_id] = AnalysisStatus.ERROR

@app.options("/{rest_of_path:path}")
async def options_handler(rest_of_path: str):
    return JSONResponse(
        content={"message": "CORS preflight"},
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "*",
            "Access-Control-Allow-Headers": "*",
        }
    )

@app.get("/api/library/sources")
async def get_library_sources(query: Optional[str] = None, page: int = 1):
    """–ü–æ–∏—Å–∫ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ"""
    try:
        user_id = "demo_user"
        if query:
            return await library_service.search_sources(user_id, query, page)
        else:
            return await library_service.get_user_sources(user_id, page)
    except Exception as e:
        logger.error(f"Error getting sources: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/library/sources")
async def get_library_sources(query: Optional[str] = None, page: int = 1):
    """–ü–æ–∏—Å–∫ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ"""
    try:
        user_id = "demo_user"
        if query:
            return await library_service.search_sources(user_id, query, page)
        else:
            return await library_service.get_user_sources(user_id, page)
    except Exception as e:
        logger.error(f"Error getting sources: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/debug/bibliography-search")
async def debug_bibliography_search(entry_text: str = "–ì—Ä–∞—á–µ–≤, –°. –ê., –ì—É–Ω–¥–æ—Ä–æ–≤–∞, –ú. –ê. –ë–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ"):
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–∏—Å–∫–∞ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏"""
    try:
        from app.bibliography.checker import BibliographyChecker

        checker = BibliographyChecker()

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–∏—Å–∫
        result = checker._search_in_library(entry_text, [entry_text])

        return {
            "success": True,
            "entry_text": entry_text,
            "library_match": result,
            "library_service_available": hasattr(checker, 'library_service') and checker.library_service is not None,
            "user_sources_count": len(checker.library_service.sources.get("demo_user", [])) if hasattr(checker,
                                                                                                       'library_service') else 0
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

@app.get("/api/library/sources/{source_id}")
async def get_source_details(source_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–µ"""
    try:
        user_id = "demo_user"
        result = await library_service.get_source_details(user_id, source_id)

        if not result["success"]:
            raise HTTPException(status_code=404, detail=result["message"])

        return result
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting source details: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/library/sources/{source_id}/download")
async def download_source_file(source_id: str):
    """–°–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
    try:
        user_id = "demo_user"
        source_result = await library_service.get_source_details(user_id, source_id)

        if not source_result['success']:
            raise HTTPException(status_code=404, detail="–ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω")

        source = source_result['source']
        file_path = source.get('file_path')

        if not file_path or not os.path.exists(file_path):
            print(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            raise HTTPException(status_code=404, detail="–§–∞–π–ª –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω")

        # –ü–æ–ª—É—á–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è –∏–∑ –ø—É—Ç–∏
        filename = source.get('filename') or os.path.basename(file_path)

        print(f"‚úÖ –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞: {file_path}")
        print(f"üìÅ –ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {filename}")
        print(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {os.path.getsize(file_path) if os.path.exists(file_path) else 0} –±–∞–π—Ç")

        return FileResponse(
            path=file_path,
            filename=filename,
            media_type='application/octet-stream',
            headers={
                'Content-Disposition': f'attachment; filename="{filename}"'
            }
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}")


@app.get("/api/debug/source-files")
async def debug_source_files():
    """–û—Ç–ª–∞–¥–∫–∞ —Ñ–∞–π–ª–æ–≤ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    try:
        user_id = "demo_user"
        user_sources = library_service.sources.get(user_id, [])

        file_info = []

        for source in user_sources:
            file_path = source.get('file_path')
            exists = os.path.exists(file_path) if file_path else False

            file_info.append({
                'id': source.get('id'),
                'title': source.get('title'),
                'filename': source.get('filename'),
                'file_path': file_path,
                'exists': exists,
                'has_file': source.get('has_file', False),
                'size': os.path.getsize(file_path) if exists and file_path else 0
            })

        return {
            "success": True,
            "total_sources": len(user_sources),
            "files": file_info
        }
    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }

@app.delete("/api/library/sources/{source_id}")
async def delete_from_library(source_id: str):
    """–£–¥–∞–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏"""
    try:
        user_id = "demo_user"
        return await library_service.delete_source(user_id, source_id)
    except Exception as e:
        logger.error(f"Error deleting source: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/library/sources/{source_id}/full-content")
async def get_source_full_content(source_id: str):
    """–ü–æ–ª—É—á–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
    try:
        user_id = "demo_user"
        result = await library_service.get_source_details(user_id, source_id)

        if not result["success"]:
            raise HTTPException(status_code=404, detail=result["message"])

        source = result["source"]
        full_content = source.get('full_content', '')

        if not full_content:
            raise HTTPException(status_code=404, detail="–¢–µ–∫—Å—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω")

        return {
            "success": True,
            "source_id": source_id,
            "title": source.get("title"),
            "full_content": full_content,
            "content_length": len(full_content)
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error getting full content: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/library/sources/{source_id}/content")
async def get_source_content(source_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
    try:
        user_id = "demo_user"
        result = await library_service.get_source_content(user_id, source_id)

        if not result["success"]:
            raise HTTPException(status_code=404, detail=result["message"])

        return result
    except Exception as e:
        logger.error(f"Error getting source content: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/library/verify-citation")
async def verify_citation_content(verification_data: dict):
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ü–∏—Ç–∞—Ç—ã —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
    try:
        user_id = "demo_user"
        citation_text = verification_data.get('citation_text')
        source_id = verification_data.get('source_id')

        if not citation_text or not source_id:
            raise HTTPException(status_code=400, detail="–ù–µ–æ–±—Ö–æ–¥–∏–º—ã citation_text –∏ source_id")

        return await library_service.verify_citation_content(user_id, citation_text, source_id)
    except Exception as e:
        logger.error(f"Error verifying citation: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/library/sources/with-content")
async def add_source_with_content(source_data: dict):
    """–î–æ–±–∞–≤–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ —Å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ–º"""
    try:
        user_id = "demo_user"
        content = source_data.pop('content', None)  # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å

        return await library_service.add_source(user_id, source_data, content)
    except Exception as e:
        logger.error(f"Error adding source with content: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/library/sources/upload")
async def upload_source_file(file: UploadFile = File(...)):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ñ–∞–π–ª –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫—É"""
    try:
        user_id = "demo_user"
        print(f"API: Uploading source file: {file.filename}")

        # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
        print(f"API: File size: {file.size if hasattr(file, 'size') else 'unknown'}")
        print(f"API: File content type: {file.content_type}")

        result = await library_service.add_source_from_file(user_id, file)

        print(f"API: Upload result: {result}")

        if not result.get("success"):
            raise HTTPException(status_code=400, detail=result.get("message", "Upload failed"))

        return result
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Error uploading source file: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")

@app.post("/api/library/sources/manual")
async def add_manual_source(source_data: dict):
    """–î–æ–±–∞–≤–ª—è–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫ —á–µ—Ä–µ–∑ —Ä—É—á–Ω–æ–π –≤–≤–æ–¥"""
    try:
        user_id = "demo_user"
        return await library_service.add_source(user_id, source_data)
    except Exception as e:
        logger.error(f"Error adding manual source: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/debug/sources/{source_id}/parse-info")
async def debug_parse_info(source_id: str):
    """–û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–∞—Ä—Å–∏–Ω–≥–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
    try:
        user_id = "demo_user"
        result = await library_service.get_source_details(user_id, source_id)

        if not result["success"]:
            return {
                "success": False,
                "message": result["message"]
            }

        source = result["source"]

        debug_info = {
            "source_id": source_id,
            "title": source.get("title"),
            "has_file": source.get("has_file", False),
            "file_path": source.get("file_path"),
            "file_exists": os.path.exists(source.get("file_path", "")) if source.get("file_path") else False,
            "has_content": source.get("has_content", False),
            "has_full_content": source.get("has_full_content", False),
            "content_length": source.get("content_length", 0),
            "content_preview_length": len(source.get("content_preview", "")),
            "text_length": source.get("text_length", 0)
        }

        # –ü–æ–ø—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–ø–∞—Ä—Å–∏—Ç—å —Ñ–∞–π–ª –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        if source.get("file_path") and os.path.exists(source.get("file_path")):
            try:
                from app.services.simple_source_processor import SimpleSourceProcessor
                from pathlib import Path

                processor = SimpleSourceProcessor()
                file_path = Path(source['file_path'])

                debug_info["file_info"] = {
                    "size": file_path.stat().st_size if file_path.exists() else 0,
                    "extension": file_path.suffix,
                    "exists": file_path.exists(),
                    "last_modified": datetime.fromtimestamp(
                        file_path.stat().st_mtime).isoformat() if file_path.exists() else None
                }

                # –ü—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∑–∞–Ω–æ–≤–æ
                reextracted = await processor.extract_text_from_file(file_path)
                debug_info["reparse"] = {
                    "success": bool(reextracted and reextracted.strip()),
                    "length": len(reextracted),
                    "preview": reextracted[:200] if reextracted else ""
                }

                # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
                saved_content = source.get('full_content', '')
                debug_info["comparison"] = {
                    "same_length": len(reextracted) == len(saved_content),
                    "reextracted_length": len(reextracted),
                    "saved_length": len(saved_content),
                    "difference": abs(len(reextracted) - len(saved_content))
                }

            except Exception as e:
                debug_info["reparse_error"] = str(e)

        return {
            "success": True,
            "debug_info": debug_info
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@app.get("/api/debug/storage")
async def debug_storage():
    """–û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ"""
    try:
        data_dir = Path("data/library")
        contents_dir = data_dir / "contents"

        storage_info = {
            "data_dir": str(data_dir),
            "data_dir_exists": data_dir.exists(),
            "contents_dir": str(contents_dir),
            "contents_dir_exists": contents_dir.exists(),
            "total_sources": library_service.get_all_sources_count() if hasattr(library_service,
                                                                                'get_all_sources_count') else "N/A"
        }

        if contents_dir.exists():
            content_files = list(contents_dir.glob("*.txt"))
            storage_info["content_files"] = {
                "count": len(content_files),
                "files": [str(f.name) for f in content_files[:10]],  # –ü–µ—Ä–≤—ã–µ 10 —Ñ–∞–π–ª–æ–≤
                "total_size": sum(f.stat().st_size for f in content_files)
            }

        return {
            "success": True,
            "storage_info": storage_info
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@app.get("/api/library/stats")
async def get_library_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏"""
    try:
        user_id = "demo_user"
        user_sources = library_service.sources.get(user_id, [])

        stats = {
            "total_sources": len(user_sources),
            "sources_with_files": len([s for s in user_sources if s.get('has_file')]),
            "sources_with_content": len([s for s in user_sources if s.get('has_content')]),
            "sources_by_type": {},
            "total_content_size": 0
        }

        # –°—á–∏—Ç–∞–µ–º –ø–æ —Ç–∏–ø–∞–º
        for source in user_sources:
            source_type = source.get('source_type', 'unknown')
            stats["sources_by_type"][source_type] = stats["sources_by_type"].get(source_type, 0) + 1

            if source.get('text_length'):
                stats["total_content_size"] += source.get('text_length', 0)

        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏
        if user_sources:
            stats["oldest_source"] = min(s.get('created_at', '') for s in user_sources)
            stats["newest_source"] = max(s.get('created_at', '') for s in user_sources)

        return {
            "success": True,
            "stats": stats
        }

    except Exception as e:
        logger.error(f"Error getting library stats: {e}")
        return {
            "success": False,
            "error": str(e)
        }


@app.post("/api/check-citations-in-library")
async def check_citations_in_library(check_request: dict):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ü–∏—Ç–∞—Ç—ã –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–µ"""
    try:
        user_id = "demo_user"

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_sources = library_service.sources.get(user_id, [])

        if not user_sources:
            return {
                "success": False,
                "message": "–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø—É—Å—Ç–∞",
                "results": []
            }

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç—ã –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        source_texts = []
        for source in user_sources:
            if source.get('has_content'):
                source_texts.append({
                    'id': source['id'],
                    'title': source.get('title', ''),
                    'full_content': source.get('full_content', ''),
                    'authors': source.get('authors', []),
                    'year': source.get('year')
                })

        checker = BibliographyChecker()
        results = []

        # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —Ü–∏—Ç–∞—Ç–∞–º –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
        for citation_data in check_request.get('citations', []):
            citation_text = citation_data.get('text', '')
            context = citation_data.get('context', '')

            if citation_text and context:
                result = checker.find_citation_in_sources(citation_text, context, source_texts)
                results.append(result)

        return {
            "success": True,
            "total_citations_checked": len(results),
            "total_sources_searched": len(source_texts),
            "results": results
        }

    except Exception as e:
        logger.error(f"Error checking citations: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/find-specific-citation")
async def find_specific_citation(citation_data: dict):
    """–ò—â–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —Ü–∏—Ç–∞—Ç—É –≤ –±–∏–±–ª–∏–æ—Ç–µ–∫–µ"""
    try:
        user_id = "demo_user"
        citation_text = citation_data.get('citation_text', '')
        context = citation_data.get('context', '')

        if not citation_text or not context:
            raise HTTPException(
                status_code=400,
                detail="–ù–µ–æ–±—Ö–æ–¥–∏–º—ã citation_text –∏ context"
            )

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_sources = library_service.sources.get(user_id, [])

        if not user_sources:
            return {
                "success": False,
                "message": "–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø—É—Å—Ç–∞",
                "citation_text": citation_text
            }

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç—ã –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        source_texts = []
        for source in user_sources:
            if source.get('has_content'):
                source_texts.append({
                    'id': source['id'],
                    'title': source.get('title', ''),
                    'full_content': source.get('full_content', ''),
                    'authors': source.get('authors', []),
                    'year': source.get('year')
                })

        checker = BibliographyChecker()
        result = checker.find_citation_in_sources(citation_text, context, source_texts)

        return {
            "success": True,
            "citation_text": citation_text,
            "context": context,
            "search_results": result
        }

    except Exception as e:
        logger.error(f"Error finding citation: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/verify-citation-semantically")
async def verify_citation_semantically(verification_data: dict):
    """–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ü–∏—Ç–∞—Ç—ã –≤ –∏—Å—Ç–æ—á–Ω–∏–∫–µ"""
    try:
        user_id = "demo_user"

        citation_data = verification_data.get('citation_data')
        source_id = verification_data.get('source_id')

        if not citation_data or not source_id:
            raise HTTPException(
                status_code=400,
                detail="–ù–µ–æ–±—Ö–æ–¥–∏–º—ã citation_data –∏ source_id"
            )

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        source_result = await library_service.get_source_details(user_id, source_id)
        if not source_result["success"]:
            raise HTTPException(status_code=404, detail="–ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω")

        # –í—ã–ø–æ–ª–Ω—è–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
        from app.bibliography.checker import BibliographyChecker
        checker = BibliographyChecker()

        result = checker.verify_citation_semantically(citation_data, source_result["source"])

        return {
            "success": True,
            "verification_result": result,
            "citation_preview": citation_data.get('text', '')[:100],
            "source_title": source_result["source"].get('title')
        }

    except Exception as e:
        logger.error(f"Error in semantic verification: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/api/batch-verify-citations")
async def batch_verify_citations(batch_data: dict):
    """–ü–∞–∫–µ—Ç–Ω–∞—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ü–∏—Ç–∞—Ç"""
    try:
        user_id = "demo_user"

        citations = batch_data.get('citations', [])
        source_id = batch_data.get('source_id')

        if not citations or not source_id:
            raise HTTPException(
                status_code=400,
                detail="–ù–µ–æ–±—Ö–æ–¥–∏–º—ã citations –∏ source_id"
            )

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        source_result = await library_service.get_source_details(user_id, source_id)
        if not source_result["success"]:
            raise HTTPException(status_code=404, detail="–ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω")

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–∞–∫–µ—Ç–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
        from app.semantic_matcher import semantic_matcher

        result = semantic_matcher.batch_verify_citations(citations, source_result["source"])

        return {
            "success": True,
            "batch_result": result,
            "source_info": {
                "id": source_id,
                "title": source_result["source"].get('title')
            }
        }

    except Exception as e:
        logger.error(f"Error in batch verification: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/debug/semantic-match/{source_id}/{citation_id}")
async def debug_semantic_match(source_id: str, citation_id: str):
    """–û—Ç–ª–∞–¥–æ—á–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è"""
    try:
        user_id = "demo_user"

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        source_result = await library_service.get_source_details(user_id, source_id)
        if not source_result["success"]:
            return {
                "success": False,
                "error": "–ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω"
            }

        # –í —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏ –∑–¥–µ—Å—å –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —Ü–∏—Ç–∞—Ç—É –ø–æ citation_id
        # –î–ª—è –¥–µ–º–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—É—é —Ü–∏—Ç–∞—Ç—É
        test_citation = {
            "id": citation_id,
            "text": "–ú–µ—Ç–æ–¥—ã –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö –≤ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö",
            "context": "–í —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö –≤—Å–µ –±–æ–ª—å—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∏–æ–±—Ä–µ—Ç–∞—é—Ç –º–µ—Ç–æ–¥—ã –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö...",
            "full_paragraph": "–í —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö –≤—Å–µ –±–æ–ª—å—à–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø—Ä–∏–æ–±—Ä–µ—Ç–∞—é—Ç –º–µ—Ç–æ–¥—ã –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è—é—Ç –≤—ã—è–≤–ª—è—Ç—å —Å–∫—Ä—ã—Ç—ã–µ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏ –∏ –¥–µ–ª–∞—Ç—å –æ–±–æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–æ–≥–Ω–æ–∑—ã."
        }

        from app.semantic_matcher import semantic_matcher

        # –ù–∞—Ö–æ–¥–∏–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        matches = semantic_matcher.find_semantic_matches(
            test_citation['full_paragraph'],
            source_result['source'].get('full_content', '')
        )

        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å
        similarity = semantic_matcher.calculate_semantic_similarity(
            test_citation['full_paragraph'],
            source_result['source'].get('full_content', '')
        )

        return {
            "success": True,
            "source_id": source_id,
            "citation": test_citation,
            "semantic_similarity": similarity,
            "matches_found": len(matches),
            "top_matches": matches[:3] if matches else []
        }

    except Exception as e:
        return {
            "success": False,
            "error": str(e)
        }


@app.post("/documents/{doc_id}/semantic-check")
async def start_semantic_check(doc_id: str, background_tasks: BackgroundTasks):
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        result = analysis_service.get_analysis_result(doc_id)
        if not result:
            raise HTTPException(status_code=404, detail="Document analysis not found")

        # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –≤ —Ñ–æ–Ω–µ
        background_tasks.add_task(
            analysis_service.perform_semantic_check,
            doc_id
        )

        return {
            "success": True,
            "message": "–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–ø—É—â–µ–Ω–∞ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ",
            "doc_id": doc_id
        }

    except Exception as e:
        logger.error(f"Error starting semantic check: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/documents/{doc_id}/semantic-status")
async def get_semantic_status(doc_id: str):
    """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç—É—Å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏"""
    try:
        result = analysis_service.get_analysis_result(doc_id)
        if not result:
            raise HTTPException(status_code=404, detail="Document analysis not found")

        semantic_stats = result.get('semantic_verification_stats', {})

        return {
            "success": True,
            "doc_id": doc_id,
            "semantic_check_available": result.get('semantic_check_available', False),
            "semantic_check_pending": result.get('semantic_check_pending', True),
            "semantic_stats": semantic_stats,
            "citations_count": len(result.get('citations', [])),
            "verified_citations": len([c for c in result.get('citations', []) if c.get('is_verified', False)])
        }

    except Exception as e:
        logger.error(f"Error getting semantic status: {e}")
        raise HTTPException(status_code=500, detail=str(e))
@app.get("/")
async def root():
    return {"message": "Citation Checker API"}


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=8001, reload=True)