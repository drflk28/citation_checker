import requests
import time
import logging
import re
import xml.etree.ElementTree as ET
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from urllib.parse import urlencode, quote
from app.config import APIConfig

@dataclass
class SearchResult:
    source: str
    title: Optional[str] = None
    authors: List[str] = None
    year: Optional[str] = None
    publisher: Optional[str] = None
    journal: Optional[str] = None
    volume: Optional[str] = None
    issue: Optional[str] = None
    pages: Optional[str] = None
    doi: Optional[str] = None
    isbn: Optional[str] = None
    url: Optional[str] = None
    confidence: float = 0.0
    relevance_score: float = 0.0
    is_search_link: bool = False

class OnlineSearcher:
    def __init__(self, config: APIConfig):
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.session = requests.Session()

        # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç API
        self.api_priority = [
            'crossref',  # –ù–∞—É—á–Ω—ã–µ —Å—Ç–∞—Ç—å–∏
            'open_library',  # –ö–Ω–∏–≥–∏
            'arxiv',  # –ù–∞—É—á–Ω—ã–µ –ø—Ä–µ–ø—Ä–∏–Ω—Ç—ã
            'google_books'  # –ö–Ω–∏–≥–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å API key)
        ]

        self.session.headers.update({
            'User-Agent': 'AcademicCitationChecker/1.0',
            'Accept': 'application/json'
        })

    def _generate_search_queries(self, text: str) -> List[str]:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        import re

        queries = []

        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
        clean_text = re.sub(r'\[.*?\]|\(.*?\)|\/\/.*|:.*?[;,]', '', text)
        clean_text = re.sub(r'\s+', ' ', clean_text.strip())

        print(f"  –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –¥–ª—è: '{clean_text}'")

        # 1. –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—Ä–æ—Å: –∞–≤—Ç–æ—Ä—ã + –Ω–∞–∑–≤–∞–Ω–∏–µ
        main_query = self._create_main_query(clean_text)
        if main_query and len(main_query) > 3:
            print(f"  –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—Ä–æ—Å: '{main_query}'")
            queries.append(main_query)

        # 2. –ó–∞–ø—Ä–æ—Å —Ç–æ–ª—å–∫–æ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º (–µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å)
        title_only = self._extract_main_title_for_search(clean_text)  # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –º–µ—Ç–æ–¥
        if title_only and len(title_only) > 5 and title_only != main_query:
            print(f"  –ó–∞–ø—Ä–æ—Å –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é: '{title_only}'")
            queries.append(title_only)

            # –î–æ–±–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —Ç–∏–ø–∞
            if any(word in clean_text.lower() for word in ['—É—á–µ–±–Ω–∏–∫', '–ø–æ—Å–æ–±–∏–µ', '—É—á–µ–±–Ω–æ–µ']):
                queries.append(f'"{title_only}" —É—á–µ–±–Ω–∏–∫')
                queries.append(f'"{title_only}" –∫–Ω–∏–≥–∞')

        # 3. –ó–∞–ø—Ä–æ—Å –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        if any(word in clean_text.lower() for word in ['book', 'textbook', 'manual']):
            eng_words = re.findall(r'\b[a-zA-Z]{4,}\b', clean_text)
            if eng_words:
                eng_query = ' '.join(eng_words[:6])
                if eng_query and eng_query not in queries:
                    queries.append(eng_query)

        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –ø—É—Å—Ç—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        unique_queries = []
        seen = set()
        for query in queries:
            if query and len(query) > 2 and query not in seen:
                seen.add(query)
                unique_queries.append(query)

        print(f"  –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {unique_queries}")
        return unique_queries[:3]

    def search_publication(self, query: str, max_results: int = 5) -> List[SearchResult]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π"""
        print(f"üîç –ü–æ–∏—Å–∫ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏: '{query}'")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        search_queries = self._generate_search_queries(query)

        if not search_queries:
            print("  ‚ö† –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã")
            return []

        all_results = []

        for search_query in search_queries:
            if len(all_results) >= max_results:
                break

            print(f"  –ó–∞–ø—Ä–æ—Å: '{search_query}'")
            query_results = []

            for api_name in self.api_priority:
                if len(query_results) >= 3:
                    break

                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º Google Books –µ—Å–ª–∏ –Ω–µ—Ç API key
                if api_name == 'google_books' and not self.config.GOOGLE_BOOKS_API_KEY:
                    print(f"    ‚ö† {api_name} –ø—Ä–æ–ø—É—â–µ–Ω (–Ω–µ—Ç API key)")
                    continue

                try:
                    print(f"    –ò—Å–ø–æ–ª—å–∑—É–µ–º {api_name}...")
                    api_results = self._call_api(api_name, search_query)
                    if api_results:
                        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                        relevant_results = [r for r in api_results if self._is_relevant_result(r, query)]
                        query_results.extend(relevant_results)

                        print(
                            f"    ‚úÖ {api_name}: –Ω–∞–π–¥–µ–Ω–æ {len(api_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, {len(relevant_results)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö")
                        time.sleep(0.3)
                    else:
                        print(f"    ‚ùå {api_name}: —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ—Ç")
                except Exception as e:
                    print(f"    ‚ö† –û—à–∏–±–∫–∞ –≤ {api_name}: {e}")
                    continue

            all_results.extend(query_results)

        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∏ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
        final_results = self._deduplicate_results(all_results)[:max_results]
        print(f"üéØ –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {len(final_results)}")

        # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        for i, result in enumerate(final_results):
            rel_status = "‚úÖ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π" if self._is_relevant_result(result, query) else "‚ö† –ù–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π"
            print(f"      {rel_status} —Ä–µ–∑—É–ª—å—Ç–∞—Ç: '{result.title}' (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result.confidence:.2f})")

        return final_results

    def _call_api(self, api_name: str, query: str) -> List[SearchResult]:
        """–í—ã–∑–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ API"""
        if api_name == 'google_books':
            return self._search_google_books(query)
        elif api_name == 'crossref':
            return self._search_crossref(query)
        elif api_name == 'open_library':
            return self._search_open_library(query)
        elif api_name == 'arxiv':
            return self._search_arxiv(query)
        return []

    def _search_crossref(self, query: str) -> List[SearchResult]:
        """–ü–æ–∏—Å–∫ –≤ CrossRef API –¥–ª—è –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π"""
        try:
            params = {
                'query': query,
                'rows': 5,
                'select': 'DOI,title,author,issued,publisher,container-title,volume,issue,page,type'
            }

            response = self.session.get(
                'https://api.crossref.org/works',
                params=params,
                timeout=10
            )

            if response.status_code == 200:
                data = response.json()
                return self._parse_crossref_results(data)
            else:
                print(f"Crossref API status: {response.status_code}")

        except Exception as e:
            print(f"Crossref API error: {e}")

        return []

    def _parse_crossref_results(self, data: Dict) -> List[SearchResult]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Crossref —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π"""
        results = []

        for item in data['message'].get('items', [])[:5]:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ç–∏–ø—ã
            item_type = item.get('type')
            if item_type not in ['journal-article', 'book', 'proceedings-article', 'book-chapter']:
                continue

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å—Ç–∞—Ç—å–∏ —Å –∫–æ—Ä–æ—Ç–∫–∏–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —ç—Ç–æ –Ω–µ –∫–Ω–∏–≥–∏)
            title = item.get('title', [''])[0] if item.get('title') else ''
            if len(title) < 20 and item_type != 'journal-article':
                continue

            authors = []
            for author in item.get('author', []):
                name = f"{author.get('given', '')} {author.get('family', '')}".strip()
                if name:
                    authors.append(name)

            year = None
            if item.get('issued', {}).get('date-parts', [[]])[0]:
                year = str(item['issued']['date-parts'][0][0])

            # –í—ã—á–∏—Å–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ –∏ –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö
            confidence = self._calculate_crossref_confidence(item, title)

            result = SearchResult(
                source='crossref',
                title=title,
                authors=authors,
                year=year,
                publisher=item.get('publisher'),
                journal=item.get('container-title', [''])[0] if item.get('container-title') else None,
                volume=item.get('volume'),
                issue=item.get('issue'),
                pages=item.get('page'),
                doi=item.get('DOI'),
                url=f"https://doi.org/{item.get('DOI')}" if item.get('DOI') else None,
                confidence=confidence
            )
            results.append(result)

        return sorted(results, key=lambda x: x.confidence, reverse=True)

    def _calculate_crossref_confidence(self, item: Dict, title: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è Crossref —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        confidence = 0.0

        # –ë–∞–∑–æ–≤—ã–µ –±–∞–ª–ª—ã
        if item.get('DOI'):
            confidence += 0.3
        if title:
            confidence += 0.2
        if item.get('author'):
            confidence += 0.2
        if item.get('publisher'):
            confidence += 0.1
        if item.get('issued'):
            confidence += 0.1

        # –ë–æ–Ω—É—Å—ã –∑–∞ —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        item_type = item.get('type')
        if item_type == 'book':
            confidence += 0.3
        elif item_type == 'journal-article':
            confidence += 0.1

        # –®—Ç—Ä–∞—Ñ –∑–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è (–≤–æ–∑–º–æ–∂–Ω–æ –Ω–µ–ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
        if len(title) < 30:
            confidence -= 0.2

        return max(0.1, min(confidence, 1.0))

    def _search_open_library(self, query: str) -> List[SearchResult]:
        """–ü–æ–∏—Å–∫ –≤ Open Library API"""
        try:
            params = {
                'q': query,
                'limit': 5
            }

            response = self.session.get(
                'https://openlibrary.org/search.json',
                params=params,
                timeout=10
            )

            if response.status_code == 200:
                data = response.json()
                return self._parse_open_library_results(data)

        except Exception as e:
            print(f"Open Library API error: {e}")

        return []

    def _parse_open_library_results(self, data: Dict) -> List[SearchResult]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Open Library"""
        results = []

        for doc in data.get('docs', [])[:5]:
            authors = doc.get('author_name', [])
            year = doc.get('first_publish_year')

            result = SearchResult(
                source='open_library',
                title=doc.get('title'),
                authors=authors,
                year=str(year) if year else None,
                publisher=doc.get('publisher', [None])[0] if doc.get('publisher') else None,
                isbn=doc.get('isbn', [None])[0] if doc.get('isbn') else None,
                url=f"https://openlibrary.org{doc.get('key')}" if doc.get('key') else None,
                confidence=self._calculate_open_library_confidence(doc)
            )
            results.append(result)

        return sorted(results, key=lambda x: x.confidence, reverse=True)

    def _search_arxiv(self, query: str) -> List[SearchResult]:
        """–ü–æ–∏—Å–∫ –≤ ArXiv API"""
        try:
            # –ö–æ–¥–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è URL
            encoded_query = quote(query)
            url = f"http://export.arxiv.org/api/query?search_query=all:{encoded_query}&max_results=5&sortBy=relevance"

            response = self.session.get(url, timeout=10)

            if response.status_code == 200:
                return self._parse_arxiv_results(response.text)
            else:
                print(f"ArXiv API status: {response.status_code}")

        except Exception as e:
            print(f"ArXiv API error: {e}")

        return []

    def _parse_arxiv_results(self, xml_content: str) -> List[SearchResult]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ArXiv (XML)"""
        try:
            root = ET.fromstring(xml_content)
            results = []

            # ArXiv –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –∏–º–µ–Ω
            ns = {'atom': 'http://www.w3.org/2005/Atom'}

            for entry in root.findall('atom:entry', ns):
                title_elem = entry.find('atom:title', ns)
                summary_elem = entry.find('atom:summary', ns)
                published_elem = entry.find('atom:published', ns)

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–≤—Ç–æ—Ä–æ–≤
                authors = []
                for author in entry.findall('atom:author', ns):
                    name_elem = author.find('atom:name', ns)
                    if name_elem is not None:
                        authors.append(name_elem.text)

                # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ–¥ –∏–∑ –¥–∞—Ç—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–∏
                year = None
                if published_elem is not None and published_elem.text:
                    year = published_elem.text[:4]

                # ID ArXiv
                id_elem = entry.find('atom:id', ns)
                arxiv_id = None
                if id_elem is not None:
                    arxiv_id = id_elem.text.split('/')[-1]

                result = SearchResult(
                    source='arxiv',
                    title=title_elem.text if title_elem is not None else None,
                    authors=authors,
                    year=year,
                    url=f"https://arxiv.org/abs/{arxiv_id}" if arxiv_id else None,
                    confidence=0.7
                )
                results.append(result)

            return results

        except Exception as e:
            print(f"ArXiv parsing error: {e}")
            return []

    def _calculate_open_library_confidence(self, doc: Dict) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è Open Library —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        confidence = 0.0
        if doc.get('title'):
            confidence += 0.3
        if doc.get('author_name'):
            confidence += 0.3
        if doc.get('first_publish_year'):
            confidence += 0.2
        if doc.get('publisher'):
            confidence += 0.2
        return min(confidence, 1.0)

    def _deduplicate_results(self, results: List[SearchResult]) -> List[SearchResult]:
        """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ DOI, ISBN –∏–ª–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        seen = set()
        unique_results = []

        for result in results:
            key = None
            if result.doi:
                key = f"doi:{result.doi.lower()}"
            elif result.isbn:
                key = f"isbn:{result.isbn}"
            elif result.title:
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
                normalized_title = re.sub(r'[^\w]', '', result.title.lower()) if result.title else ""
                key = f"title:{normalized_title}"

            if key and key not in seen:
                seen.add(key)
                unique_results.append(result)

        return sorted(unique_results, key=lambda x: x.confidence, reverse=True)

    def _search_google_books(self, query: str) -> List[SearchResult]:
        """–ü–æ–∏—Å–∫ –≤ Google Books API"""
        try:
            if not self.config.GOOGLE_BOOKS_API_KEY:
                print("‚ö† Google Books API key –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
                return []

            params = {
                'q': query,
                'maxResults': 5,
                'key': self.config.GOOGLE_BOOKS_API_KEY
            }

            response = self.session.get(
                'https://www.googleapis.com/books/v1/volumes',
                params=params,
                timeout=10
            )

            if response.status_code == 200:
                data = response.json()
                return self._parse_google_books_results(data)
            else:
                print(f"Google Books API status: {response.status_code}")

        except Exception as e:
            print(f"Google Books API error: {e}")

        return []

    def _parse_google_books_results(self, data: Dict) -> List[SearchResult]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ Google Books"""
        results = []

        for item in data.get('items', [])[:5]:
            volume_info = item.get('volumeInfo', {})

            # –í—ã—á–∏—Å–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö
            confidence = self._calculate_confidence(volume_info)

            result = SearchResult(
                source='google_books',
                title=volume_info.get('title'),
                authors=volume_info.get('authors', []),
                year=self._extract_year_from_date(volume_info.get('publishedDate')),
                publisher=volume_info.get('publisher'),
                isbn=self._extract_isbn(volume_info.get('industryIdentifiers', [])),
                url=volume_info.get('infoLink'),
                confidence=confidence
            )
            results.append(result)

        return sorted(results, key=lambda x: x.confidence, reverse=True)

    def _calculate_confidence(self, metadata: Dict) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª–Ω–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö"""
        confidence = 0.0
        if metadata.get('title'):
            confidence += 0.3
        if metadata.get('authors'):
            confidence += 0.3
        if metadata.get('publishedDate'):
            confidence += 0.2
        if metadata.get('publisher') or metadata.get('journal'):
            confidence += 0.2
        return min(confidence, 1.0)

    def _extract_year_from_date(self, date_str: str) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≥–æ–¥ –∏–∑ —Å—Ç—Ä–æ–∫–∏ –¥–∞—Ç—ã"""
        if not date_str:
            return None
        import re
        match = re.search(r'(\d{4})', date_str)
        return match.group(1) if match else None

    def _extract_isbn(self, identifiers: List[Dict]) -> Optional[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç ISBN –∏–∑ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤"""
        for id_obj in identifiers:
            if id_obj.get('type') in ['ISBN_13', 'ISBN_10']:
                return id_obj.get('identifier')
        return None

    def _is_relevant_result(self, result: SearchResult, original_text: str) -> bool:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        if not result.title:
            return False

        original_lower = original_text.lower()
        result_title = result.title.lower()

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        original_components = self._extract_components(original_text)
        result_components = self._extract_components(result_title)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è
        if self._check_known_works(original_lower, result_title):
            return True

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
        keyword_matches = len(set(original_components['keywords']) & set(result_components['keywords']))

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–æ–≤ - –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –º–µ—Ç–æ–¥
        author_match = self._check_authors_match(original_lower, result.authors)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –≥–æ–¥—É
        year_match = (original_components.get('year') and result_components.get('year') and
                      original_components['year'] == result_components['year'])

        # –£—Å–ª–æ–≤–∏—è –¥–ª—è –ø—Ä–∏–∑–Ω–∞–Ω–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–º:
        # 1. –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–æ–≤ + —Ö–æ—Ç—è –±—ã 1 –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
        # 2. 3+ —Å–æ–≤–ø–∞–¥–∞—é—â–∏—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞
        # 3. 2+ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤–∞ + —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≥–æ–¥–∞
        if (author_match and keyword_matches >= 1) or \
                (keyword_matches >= 3) or \
                (keyword_matches >= 2 and year_match):
            return True

        # –î–ª—è –∫–Ω–∏–≥: –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
        book_keywords = ['—É—á–µ–±–Ω–∏–∫', '–ø–æ—Å–æ–±–∏–µ', 'book', 'textbook', 'manual']
        if any(keyword in result_title for keyword in book_keywords) and keyword_matches >= 2:
            return True

        return False

    def _extract_components(self, text: str) -> Dict:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        import re

        components = {
            'keywords': [],
            'year': None,
            'authors': []
        }

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–æ–¥
        year_match = re.search(r'\b(19|20)\d{2}\b', text)
        if year_match:
            components['year'] = year_match.group(0)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (—Å–ª–æ–≤–∞ –¥–ª–∏–Ω–æ–π > 3 —Å–∏–º–≤–æ–ª–æ–≤)
        words = re.findall(r'\b\w{4,}\b', text.lower())

        # –°–ø–∏—Å–æ–∫ —Å—Ç–æ–ø-—Å–ª–æ–≤ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ
        stop_words = {
            '—Ä—É—Å—Å–∫–∏–µ': {'–∏–∑–¥–∞–Ω–∏–µ', '—É—á–µ–±–Ω–∏–∫', '–ø–æ—Å–æ–±–∏–µ', '–∞–≤—Ç–æ—Ä', '–≥–æ–¥', '–∏–∑–¥', '–º–æ—Å–∫–≤–∞',
                        '—Å–∞–Ω–∫—Ç', '–ø–µ—Ç–µ—Ä–±—É—Ä–≥', '–≤–ª–∞–¥–∏–º–∏—Ä', '—á–µ–ª—è–±–∏–Ω—Å–∫', '–∏–∑–¥–∞—Ç–µ–ª—å—Å—Ç–≤–æ',
                        '—É—á–µ–±–Ω–æ–µ', '–ø—Ä–∞–∫—Ç–∏–∫—É–º', '–≤—É–∑–æ–≤', '—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', '–∏–Ω—Å—Ç–∏—Ç—É—Ç'},
            'english': {'edition', 'textbook', 'manual', 'author', 'year', 'publisher',
                        'moscow', 'petersburg', 'university', 'institute', 'press'}
        }

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
        filtered_words = []
        for word in words:
            if (word not in stop_words['—Ä—É—Å—Å–∫–∏–µ'] and
                    word not in stop_words['english'] and
                    not word.isdigit()):
                filtered_words.append(word)

        components['keywords'] = filtered_words

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∞–º–∏–ª–∏–∏ –∞–≤—Ç–æ—Ä–æ–≤ - –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –º–µ—Ç–æ–¥
        components['authors'] = self._extract_authors_for_search(text)

        return components

    def _check_known_works(self, original_text: str, result_title: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è"""
        known_works = {
            '—Ç–æ–ª—Å—Ç–æ–π': ['–≤–æ–π–Ω–∞ –∏ –º–∏—Ä', 'war and peace'],
            'orwell': ['1984', 'nineteen eighty-four'],
            '–∫–Ω—É–¥—Å–µ–Ω': ['–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ', 'machine learning'],
            '–≥—Ä–∞—á–µ–≤': ['–±–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ', 'business planning'],
            '–ª–æ–ø–∞—Ä–µ–≤–∞': ['–±–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ', 'business planning'],
            '–Ω–æ–≤–æ—Å–∞–¥': ['–±–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ', 'business planning'],
            '—É–ª–∞–Ω–æ–≤': ['—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å—Å—Ç–≤–æ', 'technological entrepreneurship'],
            '–∫–∞–º–µ–Ω–Ω–æ–≤–∞': ['–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–æ–≤', 'business process modeling'],
            '–∏–≤–∞–Ω–æ–≤': ['–º–µ—Ç–æ–¥—ã –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö', 'data analysis methods'],
            '–ø–µ—Ç—Ä–æ–≤': ['–º–µ—Ç–æ–¥—ã –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö', 'data analysis methods']
        }

        for author, works in known_works.items():
            if author in original_text:
                for work in works:
                    if work in result_title:
                        return True
        return False

    def _check_authors_match(self, original_text: str, result_authors: List[str]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∞–≤—Ç–æ—Ä–æ–≤ - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        if not result_authors:
            return False

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∞–º–∏–ª–∏–∏ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ - –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –º–µ—Ç–æ–¥
        original_authors = self._extract_authors_for_search(original_text)

        for original_author in original_authors:
            for result_author in result_authors:
                # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ —Ñ–∞–º–∏–ª–∏–∏
                if original_author.lower() in result_author.lower():
                    return True
        return False

    def _extract_authors_for_search(self, text: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞–≤—Ç–æ—Ä–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        import re

        authors = []

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∞–≤—Ç–æ—Ä–æ–≤ –∏–∑ –Ω–∞—á–∞–ª–∞ —Å—Ç—Ä–æ–∫–∏
        patterns = [
            # –†—É—Å—Å–∫–∏–µ –∞–≤—Ç–æ—Ä—ã: "–§–∞–º–∏–ª–∏—è –ò. –û." –∏–ª–∏ "–§–∞–º–∏–ª–∏—è –ò.–û."
            r'^([–ê-–Ø][–∞-—è]+(?:\s+[–ê-–Ø]\.\s*[–ê-–Ø]\.)?)',
            # –†—É—Å—Å–∫–∏–µ –∞–≤—Ç–æ—Ä—ã: "–§–∞–º–∏–ª–∏—è –ò–º—è"
            r'^([–ê-–Ø][–∞-—è]+\s+[–ê-–Ø][–∞-—è]+)',
            # –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ –∞–≤—Ç–æ—Ä—ã: "Lastname F." –∏–ª–∏ "Lastname F.I."
            r'^([A-Z][a-z]+(?:\s+[A-Z]\.(?:\s*[A-Z]\.)?)?)',
            # –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ –∞–≤—Ç–æ—Ä—ã: "Firstname Lastname"
            r'^([A-Z][a-z]+\s+[A-Z][a-z]+)'
        ]

        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                author_text = match.group(1).strip()
                # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∞–≤—Ç–æ—Ä–æ–≤ –ø–æ –∑–∞–ø—è—Ç—ã–º –∏–ª–∏ "–∏"
                author_parts = re.split(r'[,–∏]|\s+–∏\s+', author_text)

                for part in author_parts:
                    part = part.strip()
                    if part:
                        # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Ñ–∞–º–∏–ª–∏—é (–ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ)
                        surname = part.split()[0]
                        if len(surname) > 2 and surname not in authors:
                            authors.append(surname)

                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–≤—Ç–æ—Ä–æ–≤
                if len(authors) >= 2:
                    break

        return authors[:2]  # –ù–µ –±–æ–ª–µ–µ 2 –∞–≤—Ç–æ—Ä–æ–≤

    def _generate_search_queries(self, text: str) -> List[str]:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ —Å —Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∫–æ–π –Ω–∞ –∫–Ω–∏–≥–∏"""
        import re

        queries = []

        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
        clean_text = re.sub(r'\[.*?\]|\(.*?\)|\/\/.*|:.*?[;,]', '', text)

        # 1. –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–ø—Ä–æ—Å: –∞–≤—Ç–æ—Ä—ã + –∫—Ä–∞—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        main_query = self._create_main_query(clean_text)
        if main_query:
            queries.append(main_query)

        # 2. –ó–∞–ø—Ä–æ—Å —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —Ç–∏–ø–∞ –∏–∑–¥–∞–Ω–∏—è
        if any(word in clean_text.lower() for word in ['—É—á–µ–±–Ω–∏–∫', '–ø–æ—Å–æ–±–∏–µ', '—É—á–µ–±–Ω–æ–µ']):
            title_only = self._extract_main_title_for_search(clean_text)
            if title_only:
                queries.append(f'"{title_only}" —É—á–µ–±–Ω–∏–∫')
                queries.append(f'"{title_only}" –∫–Ω–∏–≥–∞')

        # 3. –ó–∞–ø—Ä–æ—Å –¥–ª—è –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        if any(word in clean_text.lower() for word in ['book', 'textbook', 'manual']):
            eng_query = self._create_english_query(clean_text)
            if eng_query:
                queries.append(eng_query)

        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        unique_queries = []
        seen = set()
        for query in queries:
            if query and query not in seen:
                seen.add(query)
                unique_queries.append(query)

        return unique_queries[:3]

    def _create_main_query(self, text: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        import re

        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
        clean_text = re.sub(r'\s+', ' ', text.strip())

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∞–≤—Ç–æ—Ä–æ–≤ (–ø–µ—Ä–≤—ã–µ 1-2 —Ñ–∞–º–∏–ª–∏–∏) - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥
        authors = self._extract_authors_for_search(clean_text)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥)
        title = self._extract_main_title_for_search(clean_text)

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
        if authors and title:
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∞–≤—Ç–æ—Ä–æ–≤ –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ
            return f"{' '.join(authors)} {title}"
        elif authors:
            # –¢–æ–ª—å–∫–æ –∞–≤—Ç–æ—Ä—ã
            return ' '.join(authors)
        elif title:
            # –¢–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏–µ
            return title
        else:
            # –†–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç - –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤
            words = clean_text.split()[:5]
            return ' '.join(words)

    def _remove_authors_from_start(self, text: str) -> str:
        """–£–±–∏—Ä–∞–µ—Ç –±–ª–æ–∫ –∞–≤—Ç–æ—Ä–æ–≤ –∏–∑ –Ω–∞—á–∞–ª–∞ —Å—Ç—Ä–æ–∫–∏"""
        import re

        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–Ω—Ü–∞ –±–ª–æ–∫–∞ –∞–≤—Ç–æ—Ä–æ–≤
        patterns = [
            r'^[^.]*?\.\s*',  # –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è —Ç–æ—á–∫–æ–π
            r'^[^,]*?,\s*',  # –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –∑–∞–ø—è—Ç–æ–π (–¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞)
            r'^[^/]*?/\s*',  # –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è —Å–ª–µ—à–µ–º
        ]

        for pattern in patterns:
            match = re.match(pattern, text)
            if match:
                return text[len(match.group(0)):]

        return text

    def _extract_main_title_for_search(self, text: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        import re

        # –£–±–∏—Ä–∞–µ–º –∞–≤—Ç–æ—Ä–æ–≤ –∏–∑ –Ω–∞—á–∞–ª–∞
        text_without_authors = self._remove_authors_from_start(text)

        # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (–¥–æ –¥–≤–æ–µ—Ç–æ—á–∏—è, —Ç–æ—á–∫–∏ –∏–ª–∏ –≥–æ–¥–∞)
        title_match = re.search(r'^([^:.]*?)(?=:\s*[–ê-–ØA-Z]|\.\s*[–ê-–ØA-Z]|\s+\d{4}|\s*$)', text_without_authors)

        if title_match:
            title = title_match.group(1).strip()
            # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤ - –£–ë–†–ê–ù –í–´–ó–û–í _extract_authors_from_text
            title = self._clean_title(title)
            return title

        return ""

    def _clean_title(self, title: str) -> str:
        """–û—á–∏—â–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤ - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        import re

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        title = re.sub(r'\s+', ' ', title.strip())

        # –£–±–∏—Ä–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ –∏ –º—É—Å–æ—Ä –≤ –Ω–∞—á–∞–ª–µ
        words = title.split()
        cleaned_words = []

        for word in words:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞ –∏ –∏–Ω–∏—Ü–∏–∞–ª—ã
            if len(word) > 2 and not re.match(r'^[–ê-–ØA-Z]\.$', word):
                cleaned_words.append(word)

        return ' '.join(cleaned_words)

    def _extract_main_title(self, text: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ –±–∏–±–ª–∏–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–π –∑–∞–ø–∏—Å–∏"""
        import re

        # –£–±–∏—Ä–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –Ω–∞—á–∞–ª–µ
        clean_text = re.sub(r'^[^–ê-–ØA-Z]*', '', text)

        # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ (–¥–æ –¥–≤–æ–µ—Ç–æ—á–∏—è –∏–ª–∏ —Ç–æ—á–∫–∏)
        title_match = re.search(r'^([^:.]*?)(?=:|\.|\s*[–ê-–Ø]\.\s*[–ê-–Ø]\.)', clean_text)
        if title_match:
            title = title_match.group(1).strip()
            # –£–±–∏—Ä–∞–µ–º –∞–≤—Ç–æ—Ä–æ–≤ –∏–∑ –Ω–∞—á–∞–ª–∞ –Ω–∞–∑–≤–∞–Ω–∏—è
            authors = self._extract_authors_for_search(title)
            for author in authors:
                title = title.replace(author, '').strip()
            return title

        return ""

    def _create_english_query(self, text: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
        import re

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        words = re.findall(r'\b[a-zA-Z]{4,}\b', text)
        if words:
            return ' '.join(words[:5])

        return ""

    def _is_likely_book(self, result: SearchResult, original_text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ—Ö–æ–∂ –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ –∫–Ω–∏–≥—É"""
        book_indicators = [
            result.source in ['google_books', 'open_library'],
            result.isbn is not None,
            '—É—á–µ–±–Ω–∏–∫' in original_text.lower() and '—É—á–µ–±' in (result.title or '').lower(),
            'book' in (result.title or '').lower() if original_text.lower().count('book') > 0 else False
        ]
        return any(book_indicators)

    def _filter_best_result(self, results: List[SearchResult], original_text: str) -> Optional[SearchResult]:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º –∫–Ω–∏–≥"""

        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –∫–Ω–∏–≥–∏
        books = [r for r in results if self._is_likely_book(r, original_text)]
        if books:
            return max(books, key=lambda x: x.confidence)

        # –ó–∞—Ç–µ–º –∏—â–µ–º —É—á–µ–±–Ω–∏–∫–∏/–ø–æ—Å–æ–±–∏—è –≤ —Å—Ç–∞—Ç—å—è—Ö
        textbooks = [r for r in results if '—É—á–µ–±' in original_text.lower() and self._is_likely_textbook(r)]
        if textbooks:
            return max(textbooks, key=lambda x: x.confidence)

        # –ò–Ω–∞—á–µ –±–µ—Ä–µ–º —Å–∞–º—ã–π —É–≤–µ—Ä–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        return max(results, key=lambda x: x.confidence) if results else None

    def _is_likely_textbook(self, result: SearchResult) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ—Ö–æ–∂ –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–∞ —É—á–µ–±–Ω–∏–∫"""
        if not result.title:
            return False
        title_lower = result.title.lower()
        textbook_indicators = [
            '—É—á–µ–±–Ω–∏–∫' in title_lower,
            'textbook' in title_lower,
            '–ø–æ—Å–æ–±–∏–µ' in title_lower,
            'manual' in title_lower
        ]
        return any(textbook_indicators)